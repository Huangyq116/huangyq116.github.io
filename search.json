[{"title":"Kafka性能测试","url":"/3.Testing/Others/Kafka性能测试/","content":"\n## 简介\n\nKafka自带监控工具Kafka-Manager，但权限控制严格，而且只能够查询Mean、1Min、5Min、15Min的数据，无法查询一个时间段内的数据，因此需要一个可供用户查询集群和Topic监控数据的工具。\n\n## Kafka监控原理\n![images](/images/20211201-1.png)\n\n## Kafka监控工具原理\nJmxtrans：解析配置文件，通过jmx采集java应用的数据采集器，他的输出可以是Graphite、StatsD、Ganglia、InfluxDB等等\nInfluxDB：开源的分布式时序、时间和指标数据库，使用go语言编写，无需外部依赖\nGrafana：开源的时序性统计和监控平台，支持influxdb 等众多的数据源，界面编辑器功能强大，自带用户权限管理\n\n![images](/images/20211201-2.png)\n\nJmx+InfluxDB+Grafana架构的优点\n- InfluxDB是时序、时间和指标数据库，非常适合存储jvm metric数据\n- Grafana这意味U时序性统计和监控平台，对于展示jvm metric监控数据也很方便，界面编辑简单，无需适配；且Grafana有简单的用户权限管理功能，可以控制不同Dashboard的访问权限。\n- Jmxtrans的推送数据是根据配置文件更新的，因此如果有增删的监控项，完全不需要跟新程序代码，修改配置即可。\n\n## Kafka安装工具\n\n### 服务 InfluxDB\n- 安装\n```shell\n# wget https://dl.influxdata.com/influxdb/releases/influxdb-1.7.8.x86_64.rpm\n# rpm -ivh influxdb-1.7.8.x86_64.rpm\n# systemctl start influxdb.service\n```\n- 配置文件\n```shell\n/etc/influxdb/influxdb.conf\n```\n\n### 服务 Granfana\n- 安装\n```shell\n# yum install https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana-4.5.2-1.x86_64.rpm\n# rpm -ivh grafana-6.0.2-1.x86_64.rpm\n#  service grafana-server start\n```\n\n\n### 服务 Jmxtrans\n- 安装\n```shell\n# yum install https://repo1.maven.org/maven2/org/jmxtrans/jmxtrans/270/jmxtrans-270.rpm\n# rpm -i jmxtrans-270.rpm --nodeps --force\n# /etc/init.d/jmxtrans start\n```\n- 配置文件\n```shell\n# jmxtrans安装目录：/usr/share/jmxtrans\n# json文件默认目录：/var/lib/jmxtrans/\n# 日志路径：/var/log/jmxtrans/jmxtrans.log\n```\n\n\n## 配置文件说明\n### 全局监控指标\n```shell\n//每秒输入的流量\n\"obj\":\"kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec\"\"attr\":[\"Count\"]\"resultAlias\":\"BytesInPerSec\"\"tags\":{\"application\":\"BytesInPerSec\"}\n```\n\n```shell\n//每秒读出的流量\n\"obj\":\"kafka.server:type=BrokerTopicMetrics,name=BytesOutPerSec\"\"attr\":[\"Count\"]\"resultAlias\":\"BytesOutPerSec\"\"tags\":{\"application\":\"BytesOutPerSec\"}\n```\n\n```shell\n//每秒输入的流量\n\"obj\":\"kafka.server:type=BrokerTopicMetrics,name=BytesRejectedPerSec\"\"attr\":[\"Count\"]\"resultAlias\":\"BytesRejectedPerSec\"\"tags\":{\"application\":\"BytesRejectedPerSec\"}\n```\n\n```shell\n//每秒消息写入总量\n\"obj\":\"kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec\"\"attr\":[\"Count\"]\"resultAlias\":\"MessagesInPerSec\"\"tags\":{\"application\":\"MessagesInPerSec\"}\n```\n\n```shell\n//每秒FetchFollower的请求次数\n\"obj\":\"kafka.network:type=RequestMetrics,name=RequestsPerSec,request=FetchFollower\"\"attr\":[\"Count\"]\"resultAlias\":\"RequestsPerSec\"\"tags\":{\"request\":\"FetchFollower\"}\n```\n\n\n```shell\n//每秒FetchConsumer的请求次数\n\"obj\":\"kafka.network:type=RequestMetrics,name=RequestsPerSec,request=FetchConsumer\"\"attr\":[\"Count\"]\"resultAlias\":\"RequestsPerSec\"\"tags\":{\"request\":\"FetchConsumer\"}\n```\n\n\n```shell\n//每秒Produce的请求次数\n\"obj\":\"kafka.network:type=RequestMetrics,name=RequestsPerSec,request=Produce\"\"attr\":[\"Count\"]\"resultAlias\":\"RequestsPerSec\"\"tags\":{\"request\":\"Produce\"}\n```\n\n\n```shell\n//内存使用的使用情况\n\"obj\":\"java.lang:type=Memory\"\"attr\":[\"HeapMemoryUsage\", \"NonHeapMemoryUsage\"]\"resultAlias\":\"MemoryUsage\"\"tags\":{\"application\":\"MemoryUsage\"}\n```\n\n```shell\n//GC的耗时和次数\n\"obj\":\"java.lang:type=GarbageCollector,name=*\"\"attr\":[\"CollectionCount\",\"CollectionTime\"]\"resultAlias\":\"GC\"\"tags\":{\"application\":\"GC\"}\n```\n\n```shell\n//每秒读出的流量\n\"obj\":\"kafka.server:type=BrokerTopicMetrics,name=BytesOutPerSec\"\"attr\":[\"Count\"]\"resultAlias\":\"BytesOutPerSec\"\"tags\":{\"application\":\"BytesOutPerSec\"}\n```\n\n```shell\n//线程的使用情况\n\"obj\":\"java.lang:type=Threading\"\"attr\":[\"PeakThreadCount\",\"ThreadCount\"]\"resultAlias\":\"Thread\"\"tags\":{\"application\":\"Thread\"}\n```\n\n```shell\n//副本落后主分片的最大消息数量\n\"obj\":\"kafka.server:type=ReplicaFetcherManager,name=MaxLag,clientId=Replica\"\"attr\":[\"Value\"]\"resultAlias\":\"ReplicaFetcherManager\"\"tags\":{\"application\":\"MaxLag\"}\n```\n\n```shell\n//该broker上的partition的数量\n\"obj\":\"kafka.server:type=ReplicaManager,name=PartitionCount\"\"attr\":[\"Value\"]\"resultAlias\":\"ReplicaManager\"\"tags\":{\"application\":\"PartitionCount\"}\n```\n\n```shell\n//正在做复制的partition的数量\n\"obj\":\"kafka.server:type=ReplicaManager,name=UnderReplicatedPartitions\"\"attr\":[\"Value\"]\"resultAlias\":\"ReplicaManager\"\"tags\":{\"application\":\"UnderReplicatedPartitions\"}\n```\n\n```shell\n//Leader的replica的数量\n\"obj\":\"kafka.server:type=ReplicaManager,name=LeaderCount\"\"attr\":[\"Value\"]\"resultAlias\":\"ReplicaManager\"\"tags\":{\"application\":\"LeaderCount\"}\n```\n\n```shell\n//一个请求FetchConsumer耗费的所有时间\n\"obj\":\"kafka.network:type=RequestMetrics,name=TotalTimeMs,request=FetchConsumer\"\"attr\":[\"Count\",\"Max\"]\"resultAlias\":\"TotalTimeMs\"\"tags\":{\"application\":\"FetchConsumer\"}\n```\n\n```shell\n//一个请求FetchFollower耗费的所有时间\n\"obj\":\"kafka.network:type=RequestMetrics,name=TotalTimeMs,request=FetchFollower\"\"attr\":[\"Count\",\"Max\"]\"resultAlias\":\"TotalTimeMs\"\"tags\":{\"application\":\"FetchFollower\"}\n```\n\n```shell\n//一个请求Produce耗费的所有时间\n\"obj\":\"kafka.network:type=RequestMetrics,name=TotalTimeMs,request=Produce\"\"attr\":[\"Count\",\"Max\"]\"resultAlias\":\"TotalTimeMs\"\"tags\":{\"application\":\"Produce\"}\n```\n\n### Topic监控指标\n\n```shell\n//topic b1f91fbe6fe54d2eaf70ef0025f1c3c2__ivc_alarm_in每秒的写入流量\n\"kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec,topic= b1f91fbe6fe54d2eaf70ef0025f1c3c2__ivc_alarm_in\"\"attr\":[\"Count\"]\"resultAlias\":\" b1f91fbe6fe54d2eaf70ef0025f1c3c2__ivc_alarm_in\"\"tags\":{\"application\":\"BytesInPerSec\"}\n```\n\n```shell\n//topic b1f91fbe6fe54d2eaf70ef0025f1c3c2__ivc_alarm_in每秒的输出流量\n\"kafka.server:type=BrokerTopicMetrics,name=BytesOutPerSec,topic= b1f91fbe6fe54d2eaf70ef0025f1c3c2__ivc_alarm_in\"\"attr\":[\"Count\"]\"resultAlias\":\" b1f91fbe6fe54d2eaf70ef0025f1c3c2__ivc_alarm_in\"\"tags\":{\"application\":\"BytesOutPerSec\"}\n```\n\n```shell\n//topic b1f91fbe6fe54d2eaf70ef0025f1c3c2__ivc_alarm_in每秒写入消息的数量\n\"obj\":\"kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec,topic= b1f91fbe6fe54d2eaf70ef0025f1c3c2__ivc_alarm_in\"\"attr\":[\"Count\"]\"resultAlias\":\" b1f91fbe6fe54d2eaf70ef0025f1c3c2__ivc_alarm_in\"\"tags\":{\"application\":\"MessagesInPerSec\"}\n```\n\n```shell\n//topic b1f91fbe6fe54d2eaf70ef0025f1c3c2__ivc_alarm_in在每个分区最后的Offset\n\"obj\":\"kafka.log:type=Log,name=LogEndOffset,topic= b1f91fbe6fe54d2eaf70ef0025f1c3c2__ivc_alarm_in,partition=*\"\"attr\":[\"Value\"]\"resultAlias\":\" b1f91fbe6fe54d2eaf70ef0025f1c3c2__ivc_alarm_in\"\"tags\":{\"application\":\"LogEndOffset\"}\n```\n\n","tags":["总结"],"categories":["3.Testing","总结"]},{"title":"Kafka串讲","url":"/3.Testing/Others/Kafka串讲/","content":"\n![images](/images/kafka/20211111-1.png)\n\n![images](/images/kafka/20211111-2.png)\n\n![images](/images/kafka/20211111-3.png)\n\n![images](/images/kafka/20211111-4.png)\n\n![images](/images/kafka/20211111-5.png)\n\n![images](/images/kafka/20211111-6.png)\n\n![images](/images/kafka/20211111-7.png)\n\n![images](/images/kafka/20211111-8.png)\n\n![images](/images/kafka/20211111-9.png)\n\n![images](/images/kafka/20211111-10.png)\n\n![images](/images/kafka/20211111-11.png)\n\n![images](/images/kafka/20211111-12.png)\n\n![images](/images/kafka/20211111-13.png)\n\n![images](/images/kafka/20211111-14.png)\n\n![images](/images/kafka/20211111-15.png)\n\n![images](/images/kafka/20211111-16.png)\n\n![images](/images/kafka/20211111-17.png)\n\n![images](/images/kafka/20211111-18.png)\n\n![images](/images/kafka/20211111-19.png)\n\n![images](/images/kafka/20211111-20.png)\n\n![images](/images/kafka/20211111-21.png)","tags":["总结"],"categories":["3.Testing","总结"]},{"title":"Python异步编程之celery","url":"/2.Programming/1.Python/Python异步编程之celery/","content":"\n## 介绍\n\n最近测试的需求里有一个既要满足异步又要满足定时的功能，第一实现想法的是使用asyncio和crontab；服务端的Yago框架中有相关插件可以同时满足两个需求，不禁思考Python中是否也有相关模块，于是乎调研了一下Celery。\n参考：\nhttps://www.cnblogs.com/Stitchez/p/10240387.html#top\nhttps://www.cnblogs.com/skyflask/p/9865378.html\n\n## 原理\n\n\u000f![images](/images/20210318-1.png)\n\nCelery中，以上组件具体功能如下：\n\n1. `任务模块 Task`：包含异步任务和定时任务。其中，异步任务通常在业务逻辑中被触发并发往任务队列，而定时任务由 Celery Beat 进程周期性地将任务发往任务队列。\n2. `消息中间件 Broker`：即为任务调度队列，接收任务生产者发来的消息（即任务），将任务存入队列。Celery 本身不提供队列服务，官方推荐使用 RabbitMQ 和 Redis 等。\n3. `任务执行单元 Worker`：是执行任务的处理单元，它实时监控消息队列，获取队列中调度的任务，并执行它。\n4. `任务结果存储 Backend `：用于存储任务的执行结果，以供查询。同消息中间件一样，存储也可使用 RabbitMQ, Redis 和 MongoDB 等。\n\n## 操作步骤\n现就Win10环境下载相关模块和中间件：\n\n```\nredis  3.2.100\nPython 3.9.0\ncelery 4.4.7\ncelery-with-redis  3.0\ncelery-with-redis 3.0\neventlet  0.22.1\n```\n\n主要的代码层面来了，我们通过流程图知道，我们需要生产任务，目录结构如下图：\n\n![images](/images/20210318-2.png)\n\n　**1、其中`__init__.py`是通过启动项目时，选择的配置文件**\n\n```python\nfrom celery import Celery\n\napp = Celery('demo')\napp.config_from_object('celery_app.celeryconfig')\n```\n\n**2、celeryconfig.py里面主要是celery的配置**\n\n```python\nfrom datetime import timedelta\nfrom celery.schedules import crontab\nBROKER_URL = 'redis://localhost:6379/1'  # 配置broker为redis\nCELERY_RESULT_BACKEND = 'redis://localhost:6379/2'  # 配置结果存储至redis\nCELERY_TIMEZONE='Asia/Shanghai'  # 时区设置\n# 导入任务\nCELERY_IMPORTS = (\n    'celery_app.task1',\n    'celery_app.task2',\n    )\n# 配置定时任务的调度器\nCELERYBEAT_SCHEDULE={\n    # 任务名字\n    'task1':{   \n        'task':'celery_app.task1.add',   # 任务启动的函数\n        'schedule':timedelta(seconds=10),    # 定时时间设置，每10秒一次\n        'args':(1,4)    # 传递的参数\n    },\n    'task2':{\n        'task':'celery_app.task2.mul',  \n        'schedule':crontab(hour=11,minute=10),   # 定时时间设置，11:10\n        'args':(2,5)\n\n    }\n}\n```\n\n**3、task1的任务**\n\n```python\nimport time\nfrom celery_app import app\n@app.task\ndef add(x, y):\n    time.sleep(3)    # 阻塞测试\n    return x + y\n```\n\n**4、task2的任务**\n\n```python\nimport time\nfrom celery_app import app\n@app.task\ndef mul(x, y):\n    time.sleep(3)\n    return x * y\n```\n\n## **运行任务**\n\n1、启动redis服务器\n\n2、在celery_app文件的上一级 shift+右键 打开命令行窗口，win10打开powershell\n\n```python\n$ celery worker -A celery_app --pool=solo -l INFO\n```\n\n3、然后打开celery beat 启动定时任务，另开一个命令行窗口\n\n```python\n$ celery beat -A celery_app -l INFO\n```\n\n4、结果如下，可以看见celery beat一直在隔10秒发送任务；至11:10处执行定时任务\n\n![images](/images/20210318-3.png)\n\n5、再来看worker\n\n![images](/images/20210318-4.png)\n\n## 其他\n\n如使用Django执行celery操作步骤可查看 [官网]( http://docs.jinkan.org/docs/celery/django/first-steps-with-django.html)\n\n","tags":["Python"],"categories":["2.Programming","Python"]},{"title":"Git中Submodule管理子项目的使用","url":"/4.ToolsNotes/Others/Git中Submodule管理子项目的使用/","content":"\n## **说明**\n\n云平台业务中，管理端代码使用微服务结构管理。模块较多，部署时间较长，针对此问题，解决方式是使用Git的Submodule子模块功能。\n\n**主要作用**\n\n子模块允许你将一个 Git 仓库作为另一个 Git 仓库的子目录。 它能让你将另一个仓库克隆到自己的项目中，同时还保持提交的独立。\n\n**详情参考**\n\n[Git工具-子模块](https://git-scm.com/book/zh/v2/Git-工具-子模块)\n\n[Git中submodule的使用](https://zhuanlan.zhihu.com/p/87053283)\n\n## **操作步骤**\n\n假定现有两个项目：project-main 和 project-sub-1;\n\n其中 project-main 表示主项目，而 project-sub-1 表示子模块项目;\n\n其中 project-main 的远程仓库地址为 https://github.com/username/project-main.git，而 project-sub-1 的远程仓库地址为 https://github.com/username/project-sub-1.git。\n\n## 使用\n\n```shell\n$ git submodule add git@github.com:username/project-sub-1.git\n```\n\n### **详情**\n\n```shell\n/d/work/github/submodule/project-main (master)$ git submodule add git@github.com:username/project-sub-1.git\nCloning into 'D:/work/github/submodule/project-main/project-sub-1'...\nremote: Enumerating objects: 3, done.\nremote: Counting objects: 100% (3/3), done.\nremote: Total 3 (delta 0), reused 3 (delta 0), pack-reused 0\nReceiving objects: 100% (3/3), done.\nwarning: LF will be replaced by CRLF in .gitmodules.\nThe file will have its original line endings in your working directory\n```\n\n### 查看\n\n```shell\n/d/work/github/submodule/project-main (master)$ git status\nOn branch master\nYour branch is up to date with 'origin/master'.\n\nChanges to be committed:\n  (use \"git restore --staged <file>...\" to unstage)\n        new file:   .gitmodules    #显示子模块的相关信息\n        new file:   project-sub-1     #显示子模块当前的版本号信息\n\n```\n\n**说明**：此时在 .git/config 文件中也会多出一些信息，在 .git/modules 文件夹下也会多出一份内容。\n\n通常此时可以使用 git commit -m \"add submodule xxx\" 提交一次，表示引入了某个子模块。\n\n提交后，在主项目仓库中，会显示出子模块文件夹，并带上其所在仓库的版本号。\n\n```shell\n/d/work/github/submodule/project-main (master)$ git commit -m \"add submodule\"\n[master d858d0a] add submodule\n 2 files changed, 4 insertions(+)\n create mode 100644 .gitmodules\n create mode 160000 project-sub-1\n```\n\n## **获取**\n\n上述步骤在创建子模块的过程中，会自动将相关代码克隆到对应路径，但对于后续使用者而言，对于主项目使用普通的 clone 操作并不会拉取到子模块中的实际代码。\n\n- 使用以下命令进行克隆，完成后 project-main/project-sub-1 文件夹是空的\n\n```shell\n/d/work/github/submodule1 (master)$ git clone git@github.com:username/project-main.git\nCloning into 'project-main'...\nremote: Enumerating objects: 8, done.\nremote: Counting objects: 100% (8/8), done.\nremote: Compressing objects: 100% (5/5), done.\nremote: Total 8 (delta 1), reused 8 (delta 1), pack-reused 0\nReceiving objects: 100% (8/8), done.\nResolving deltas: 100% (1/1), done.\n```\n\n- 如果希望子模块代码也获取到，一种方式是在克隆主项目的时候带上参数 --recurse-submodules，这样会递归地将项目中所有子模块的代码拉取。\n\n```shell\n/d/work/github/submodule1 (master)$ git clone git@github.com:Huangyq116/project-main.git --recurse-submodules\nCloning into 'project-main'...\nremote: Enumerating objects: 8, done.\nremote: Counting objects: 100% (8/8), done.\nremote: Compressing objects: 100% (5/5), done.\nremote: Total 8 (delta 1), reused 8 (delta 1), pack-reused 0\nReceiving objects: 100% (8/8), done.\nResolving deltas: 100% (1/1), done.\nSubmodule 'project-sub-1' (git@github.com:Huangyq116/project-sub-1.git) registered for path 'project-sub-1'\nCloning into 'D:/work/github/submodule1/project-main/project-sub-1'...\nremote: Enumerating objects: 10, done.\nremote: Counting objects: 100% (10/10), done.\nremote: Compressing objects: 100% (3/3), done.\nremote: Total 10 (delta 1), reused 10 (delta 1), pack-reused 0\nReceiving objects: 100% (10/10), done.\nResolving deltas: 100% (1/1), done.\nSubmodule path 'project-sub-1': checked out '196215e644fccda0a53b703a7accd2dd405bc636'\n```\n\n此时 project-main/project-sub-1 文件夹是有内容的，并且固定在某个 Git 提交的版本上。\n\n- 另外一种可行的方式是，在当前主项目中执行：\n\n```shell\n/d/work/github/submodule1/project-main (master)$git submodule init\nSubmodule 'project-sub-1' (git@github.com:username/project-sub-1.git) registered for path 'project-sub-1'\n```\n\n```shell\n/d/work/github/submodule1/project-main (master)$ git submodule update\nCloning into 'D:/work/github/submodule1/project-main/project-sub-1'...\nSubmodule path 'project-sub-1': checked out '196215e644fccda0a53b703a7accd2dd405bc636'\n```\n\n则会根据主项目的配置信息，拉取更新子模块中的代码。\n\n## **更新**\n\n对于子模块而言，并不需要知道引用自己的主项目的存在。对于自身而言，子模块是一个完整的Git仓库，按照正常的Git代码管理规范即可。\n\n对于主项目而言，子模块的内容发生变动时，通常有三种情况：\n\n1）当前项目下子模块文件夹内的内容发生了未跟踪的内容变动\n\n2）当前项目下子模块文件夹内的内容发生了版本变化\n\n3）当前项目下子模块文件夹内的内容没变，远程有更新\n\n### **子模块有未跟踪的内容变动**\n\n对于第1种情况，通常是在开发环境中，直接修改子模块文件夹中的代码导致的。\n\n此时在主项目中使用 git status 能够看到关于子模块尚未暂存以备提交的变更，但是于主项目而言是无能为力的，使用 git add/commit 对其也不会产生影响。\n\n```shell\n/d/work/github/submodule/project-main (master)$ git status\nOn branch master\nYour branch is up to date with 'origin/master'.\n\nChanges not staged for commit:\n  (use \"git add <file>...\" to update what will be committed)\n  (use \"git restore <file>...\" to discard changes in working directory)\n  (commit or discard the untracked or modified content in submodules)\n        modified:   project-sub-1 (modified content)\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\n```\n\n在此情景下，通常需要进入子模块文件夹，按照子模块内部的版本控制体系提交代码。\n\n当提交完成后，主项目的状态则进入了情况2，即当前项目下子模块文件夹内的内容发生了版本变化\n\n### **子模块有版本变化**\n\n```shell\n$ git status\nOn branch master\nYour branch is up to date with 'origin/master'.\n\nChanges not staged for commit:\n  (use \"git add <file>...\" to update what will be committed)\n  (use \"git restore <file>...\" to discard changes in working directory)\n        modified:   project-sub-1 (new commits)\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\n\n```\n\n在这种情况下，可以使用 git add/commit 将其添加到主项目的代码提交中，实际的改动就是那个子模块 文件 所表示的版本信息。\n\n### **子模块远程有更新**\n\n通常来讲，主项目与子模块的开发不会恰好是同时进行的。通常是子模块负责维护自己的版本升级后，推送到远程仓库，并告知主项目可以更新对子模块的版本依赖。\n\n在这种情况下，主项目是比较茫然的。\n\n之前曾经提到，主项目可以使用 git submodule update 更新子模块的代码，但那是指 当前主项目文件夹下的子模块目录内容 与 当前主项目记录的子模块版本 不一致时，会参考后者进行更新。\n\n但如今这种情况下，后者 当前主项目记录的子模块版本 还没有变化，在主项目看来当前情况一切正常。\n\n此时，需要让主项目主动进入子模块拉取新版代码，进行升级操作。\n\n- 通常流程是\n\n```shell\n$ cd project-sub-1 $ git pull origin master\n```\n\n子模块目录下的代码版本会发生变化，转到情况2的流程进行主项目的提交。\n\n- 当主项目的子项目特别多时，可能会不太方便，此时可以使用 git submodule 的一个命令 foreach 执行：\n\n```shell\n$ git submodule foreach 'git pull origin master'\n```\n\n### **情况汇总**\n\n- 终上所述，可知在不同场景下子模块的更新方式如下：\n- 对于子模块，只需要管理好自己的版本，并推送到远程分支即可；\n- 对于父模块，若子模块版本信息未提交，需要更新子模块目录下的代码，并执行 commit 操作提交子模块版本信息；\n- 对于父模块，若子模块版本信息已提交，需要使用 git submodule update ，Git 会自动根据子模块版本信息更新所有子模块目录的相关代码。\n\n## **删除**\n\n根据官方文档的说明，应该使用 git submodule deinit 命令卸载一个子模块。这个命令如果添加上参数 --force，则子模块工作区内即使有本地的修改，也会被移除。\n\n```shell\n$git submodule deinit project-sub-1 \n\n$git rm project-sub-1\n```\n\n- 执行 git submodule deinit project-sub-1 命令的实际效果，是自动在 .git/config 中删除了以下内容：\n\n```shell\n[submodule \"project-sub-1\"]\nurl = https://github.com/username/proproject-sub-1\n```\n\n- 执行 git rm project-sub-1 的效果，是移除了 project-sub-1 文件夹，并自动在 .gitmodules 中删除了以下内容：\n\n```shell\n[submodule \"project-sub-1\"]\n        path = project-sub-1\n        url = git@github.com:Huangyq116/project-sub-1.git\n```\n\n此时，主项目中关于子模块的信息基本已经删除:\n\n```shell\n/d/work/github/submodule/project-main (master)$ git status\nOn branch master\nYour branch is up to date with 'origin/master'.\n\nChanges to be committed:\n  (use \"git restore --staged <file>...\" to unstage)\n        modified:   .gitmodules\n        deleted:    project-sub-1\n```\n\n可以提交代码：\n\n```\ngit commit -m \"delete submodule project-sub-1\"\n```\n\n至此完成对子模块的删除。\n\n**总结**\n\n当项目比较复杂，部分代码希望独立为子模块进行版本控制时，可以使用 git submodule 功能。\n\n使用 git submodule 功能时，主项目仓库并不会包含子模块的文件，只会保留一份子模块的配置信息及版本信息，作为主项目版本管理的一部分。","tags":["Tool","Git"],"categories":["4. ToolsNotes","Tool"]},{"title":"Jenkins将Slave运行在Docker容器中","url":"/4.ToolsNotes/Jenkins/Jenkins将Slave运行在Docker容器中/","content":"\n## 说明\n\nJenkins的Master-Slave架构特点可解决多并发任务的负载问题；Master节点提供WebGUI和API功能来管理运行任务，Slave节点运行Master分配的任务；这也意味着Slave节点可以分布在不同平台并且无需安装Jenkins的完整包。\n\n## 配置\n\njenkins版本：V2.249.1\n\n### 添加node节点配置\n\n**1、首页-ManageJenkins-ManageNodesAndClouds页面，新建节点操作**\n![addnode](/images/20201214-16.png)\n\n**2、首页-新建自由风格任务选择该Slave节点**\n\n![addnode](/images/20201214-4.png)\n\n**3、运行**\n\n![run](/images/20201214-5.png)\n\n### 添加Docker节点信息\n\n**1、Jenkins首页-ManageJenkins-ManagePlugins页面，下载「Docker plugin」和「Docker Slaves Plugin」两个插件**\n\n**2、Slave机器，下载docker**\n\n![docker](/images/20201214-6.png)\n\n```shell\n1 成功下载\n2 \n3 docker pull jenkins/ssh-slave\n```\n\n因为docker默认不允许外面链接的，所以要修改配置放开：\n\n\n```shell\n修改这个文件  /usr/lib/systemd/system/docker.service中的\n\nExecStart=/usr/bin/dockerd  -H fd:// --containerd=/run/containerd/containerd.sock\n\n改成下面这个\nExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2375 -H fd:// --containerd=/run/containerd/containerd.sock\n\n然后 systemctl restart docker\n```\n\n设置docker的可执行权限：\n\n```shell\nchmod 666 /var/run/docker.sock\n```\n\n**3、Jenkins首页-ManageJenkins-ManageNodesAndClouds页面，ConfigureClouds菜单下-AddANewCloud**\n\n![docker](/images/20201214-7.png)\n\n**4、配置DOCKER CLOUD DETAILS信息；测试Slave机器docker可访问**\n\n![docker](/images/20201214-8.png)\n\n **5、配置DOCKER AGENT TEMPLATES信息**\n\n基本信息：\n\n![docker](/images/20201214-9.png)\n\n容器信息：\n\n![docker](/images/20201214-10.png)\n\n![docker](/images/20201214-11.png)\n\n**6、首页-新建自由风格任务选择该Slave节点：**\n\n![docker](/images/20201214-12.png)\n\n**7、运行：**\n\n生成镜像过程：\n\n![docker](/images/20201214-13.png)\n\n执行结果：\n\n![docker](/images/20201214-14.png)\n\n## Docker in Docker \n\n![docker](/images/20201214-15.png)\n\n参考 [Jenkins Slave in Docker](https://blog.csdn.net/qq_31977125/article/details/104000507)\n\n## 参考\n\n参考 [Jenkins通过Docker-plugin部署Slave](https://blog.csdn.net/qq_31977125/article/details/82999872)\n\n参考 [从socket权限重新认识docker架构](https://blog.csdn.net/yanggd1987/article/details/105112939)","tags":["Jenkins"],"categories":["4. ToolsNotes","Jenkins"]},{"title":"我的2020年终总结","url":"/1.Growth/年终总结/我的2020年终总结/","content":"\n\n\n\n","tags":["总结"],"categories":["1.Growth","总结"]},{"title":"初探存储对象S3","url":"/3.Testing/Others/初探存储对象S3/","content":"\n云平台测试过程中，存储服务中的对象存储之S3（Simple Storage Service简单存储服务）有着举足轻重的作用。实际业务中权限限制较多，现就测试过程中对S3的理解做简单概述。\n\n## 基本概念\n\n通过云平台提供的API，可以在任何应用、任何时间、任何地点进行文件的上传下载操作。\n\n### 开发者和用户\n\n1. 开发者：存储服务的使用者，比如某APP产品的开发者。\n\n2. 用户：开发者的用户，即某APP产品的使用者。\n\n### 空间（Bucket）\n\n1. 空间是资源的一个集合，可以理解为目录，某一个资源必须在一个空间中。\n\n2. 所有存储服务的使用者共享一个Bucket的命令空间，即如果有人用了abcd作为空间名，其他人不能再使用这个名字。\n\n3. 空间具有 私有或者公共 两种属性，用来控制空间的访问权限。\n\n### 资源（Object）\n\n1. 存储服务中最基本的单元，可以理解为文件。\n\n2. 资源名是一个字符串，可以理解为文件名。同一个bucket内，资源名必须唯一。\n\n3. 使用者可以通过良好的设计前缀，达到类似于文件目录的分类和层次效果。\n\n### 访问秘钥（Access Key）\n\n1. 云存储通过使用Access Key ID和Access Key Secret对称加密的方式来验证某个请求的发送者身份。\n\n2. 每个业务会分配唯一的一个Access Key ID，用以标志业务身份。每个业务会被分配一个Access Key Secret用以验证身份。\n\n## 业务逻辑架构图\n\n![image-20210309123201765](/images/20210312-1.png)\n\n\n\n## 测试工具\n\n“工欲善其事,必先利其器”，云平台提供了申请AK/SK及创建Bucket功能，实际测试过程中，除关注平台提供的功能外，需要额外测试服务端与存储服务系统的交互以及存储服务的有效性。测试S3存储的工具有很多，现就配置简单且为开源的工具 [s3cmd ](https://github.com/s3tools/s3cmd)进行 例：\n\n### **安装**\n\n```shell\n#yum -y install s3cmd \n```\n\n### **配置s3cmd**\n\n执行 `$ s3cmd --configure`生成配置文件，一路`Enter`，注意跳过认证并保存配置：\n\n```shell\n......\n...\nTest access with supplied credentials? [Y/n] n\n\nSave settings? [y/N] y\nConfiguration saved to '/root/.s3cfg'\n```\n\n修改以下信息：\n\n```shell\n$ vim /root/.s3cfg\naccess_key = xxx    #创建S3时获取\nsecret_key = xxx    #创建S3时获取\nhost_base = ip:port    #S3提供的集群地址\nhost_bucket = ip/kucketname    #S3用户下的一个bucket\nuse_https = False   #是否使用https\n```\n\n### **使用s3cmd**\n\n通过s3cmd --help查看具体使用方法；\n\n```shell\n$s3cmd ls   #列举所有 Buckets\n\n$s3cmd ls s3://my-bucket-name  #列举Bucket中的内容\n\n$s3cmd put file.txt s3://my-bucket-name/file.txt  #上传 file.txt 到某个 bucket\n\n$s3cmd get s3://my-bucket-name/file.txt file.txt   #下载文件\n\n$s3cmd del s3://my-bucket-name/file.txt    #删除文件\n\n$s3cmd du -H s3://my-bucket-name   #来获得对应的bucket所占用的空间大小\n```\n\n通过s3cmd操作bucket，可以独立判断出业务层逻辑正确性。\n\n其他如服务端与存储系统的交互可以使用radosgw-admin进行查看，暂不进行详细介绍。\n\n## 业务理解\n\n### Multipart原理\n\nceph默认对于单一上传文件的大小限制是5GB\n\ns3在上传大文件时，采用了multipart机制，将大文件进行分片。\n\n以下是s3cmd的两个配置\n\n```\ndefault_mime_type = binary/octet-stream #默认上传文件类型\n\nmultipart_chunk_size_mb = 15   #配置分片的大小，默认是15MB\nmultipart_max_chunks = 10000   #配置分片的最大数量，默认是1000\n```\n\n### \u000bBucket信息\n\n```shell\n#查看Bucket授权信息\n\n```\n\n\n\n","tags":["总结"],"categories":["3.Testing","总结"]},{"title":"Jenkins在不同的stage之间共享文件","url":"/4.ToolsNotes/Jenkins/Jenkins在不同的stage之间共享文件/","content":"\n在使用 k8s 或者 docker 作为 jenkins 的 slave 的时候，会出现一个问题：两个 stage 可能不再同一个机器，或者不再同一个目录上，stage A 中编译的 dist 文件， stage B 中部署需要用到的时候当前目录无法找到 dist 文件。解决方式是使用 stash 和 unstash。\n\n```shell\nstage(\"npm build\") {\n    when {\n        branch \"dev\"\n    }\n    steps {\n        sh  \"\"\"\n            npm run deploy\n        \"\"\"\n        stash includes: 'dist/**/*', name:'npm_dist'\n    }\n}\nstage(\"ansible deploy\") {\n    when {\n        branch \"dev\"\n    }\n    agent  {\n        docker {\n            image \"ansible:1.2.11\"\n        }\n    }\n    steps {\n       unstash 'npm_dist'\n       script  {\n           if (fileExists('dist.zip')) {\n               sh('rm -f  dist.zip')\n           }\n       }\n       zip zipFile: 'dist.zip',archive: false,dir: 'dist'\n       sh \"\"\"\n           ansible-playbook ansible-deploy.yml --inventory-file=hosts  -e target=dev --timeout=120\n        \"\"\"\n    }\n}\n```\n\n","tags":["Jenkins"],"categories":["4. ToolsNotes","Jenkins"]},{"title":"Jenkins触发其他项目构建","url":"/4.ToolsNotes/Jenkins/Jenkins触发其他项目构建/","content":"\n**说明**\n\n两个项目他们在 jenkins 上的任务分别是 job1 和 job2 , 在构建 job2 的时候触发 job1 的自动构建。\n\n\n\n**job1构建代码**\n\n```shell\npipeline {\n    agent {label \"XXXX1\"}\n    parameters {\n        booleanParam(name: 'enable',defaultValue: true,description: 'Checkbox parameter')\n        string(name: 'name',defaultValue: 'licong!',description: 'what is your name!')\n    }\n    stages {\n        stage(\"one\") {\n            steps {\n                echo \"${params['enable']}\"\n                echo \"${params['name']}\"\n            }\n        }\n    } \n}\n```\n\n\n\n**job2构建代码**\n\n```shell\npipeline {\n    agent {label \"XXX2\"}\n    stages {\n        stage(\"stage one\") {\n            steps {\n                echo \"done something\"\n            }\n        }\n        stage(\"stage two\") {\n            when {\n                expression {true} \n            }\n            steps {\n                 build job: './job1', parameters: [string(name: 'name', value: \"demo\"),booleanParam(name: 'enable' , value: false)]\n            }\n        }\n    } \n}\n```\n\n","tags":["Jenkins"],"categories":["4. ToolsNotes","Jenkins"]},{"title":"Jenkins在容器中编译代码","url":"/4.ToolsNotes/Jenkins/Jenkins在容器中编译代码/","content":"\n**1、声明式**\n\n```shell\nstages{\n    stage(\"go build\") {\n        agent {\n            image \"golang:1.12.1\"\n        }\n        steps {\n            sh \"\"\"\n                go build\n            \"\"\"\n        }\n    }\n}\n```\n\n**2、脚本式**\n\n```shell\nstages {\n    stage(\"go build\") {\n        steps {\n            script {\n                docker.image(\"golang:1.12.1\").inside() {\n                    sh \"\"\"\n                        go build\n                    \"\"\"\n                }\n            }\n        }\n    }\n}\n```\n\n**3、前端**\n\n```shell\nstage(\"npm build\") {\n    agent {\n        docker {\n            image \"XXX/node:1.1.3\"\n        }\n    }\n    steps {\n        sh \"\"\"\n            npm run build\n        \"\"\"\n    }\n}\n```\n\n","tags":["Jenkins"],"categories":["4. ToolsNotes","Jenkins"]},{"title":"Jenkins的权限控制","url":"/4.ToolsNotes/Jenkins/Jenkins权限控制/","content":"\n## 介绍\n\n多人使用同一套Jenkins进行操作时，会存在任务多部署慢和误操作等不方便之处，二次开发的Jenkins可以通过业务逻辑层进行权限划分，原生的Jenkins则提供了Role-based Authorization Strategy权限插件，分为管理员和普通用户，根据目录来控制用户对job的操作。\n\n**1.创建目录**\n\n在Jenkins首页点击新建任务--》输入名称test--选择文件夹--点击确定---》点击保存，目录就创建好了。\n\n![新建任务](/images/20201214-1.png)\n\n**2.添加角色**\n\n在Jenkins首页，点击系统管理--》选择Manage and Assign Roles--》点击Manage Roles—》在Project roles下，创建角色test，对test目录下的job有权限---》设置角色test的权限---》点击save，保存。\n\n![添加角色](/images/20201214-2.png)\n\n**3.分配角色**\n\n在Jenkins首页点击系统管理--》选择Manage and Assign Roles–-》选择Assign Roles—》在Item roles下，输入用户名wangqian02，点击add，选择角色---》点击save保存\n\n![分配角色](/images/20201214-3.png)\n\n至此用户wangqian02仅可以查看操作test文件里的任务了。","tags":["Jenkins"],"categories":["4. ToolsNotes","Jenkins"]},{"title":"Jenkins-pipeline使用邮件扩展发送邮件","url":"/4.ToolsNotes/Jenkins/Jenkins-pipeline使用邮件扩展发送邮件/","content":"\n### Jenkins pipeline 使用邮件扩展发送邮件\n[参考](https://www.cnblogs.com/imyalost/p/8781759.html)\n\n### Jenkins配置邮件通知 \n[参考](https://blog.51cto.com/5766902/2317533)\n\n","tags":["Jenkins"],"categories":["4. ToolsNotes","Jenkins"]},{"title":"Python基础知识","url":"/2.Programming/1.Python/Python基础知识/","content":"\n## Python垃圾回收机制\n\n1. 引用计数：在每次分配和释放内存的时候，加入引用计数的动作；当引用计数为0时，该内存就会被销毁\n2. 标记清除：标记活动对象，回收非活动对象\n3. 分带收集：Python将内存根据对象的存活时间分为不同的集合，每个集合成为一个代，共有3代，他们各对应一个链表，当年轻链表的总数达到上限时，垃圾回收机制就会被触发，把可以回收的对象回收掉，不可回收的对象则移到中年代去，以此类推。\n\n\n\n## Python缓冲池\n\n用于存储高频使用的对象，降低内存的使用；主要对象是不可变对象；\n\n1. 字符串和整型对象都是不可变对象，因此Python会很高效的缓存它们\n2. 元组tuple是不可变累类型，但是元组不支持缓存\n\n\n\n## Python中的可变参数和关键字参数\n\nfunc(*args,**kw)\n\n1. *args是可变参数，args接收的是一个tuple；既可以直接传入func(1,2,3)，又可以先组装成list或tuple，在通过args传入\n2. **kw是关键字参数，kw接收的是一个dict；既可以直接传入func(a=1,b=2)，又可以先组装成dict，再通过kw传入\n\n\n\n## Python的匿名函数\n\n关键字lambda表示匿名函数，只有一个表达式，不用写return，返回值就是该表达式的结果。\n\n```python\n匿名表达式：\nlambda x: x*x\n\n函数式：\ndef f(x):\n\treturn x*x\n```\n\n\n\n## Python装饰器\n\n本质是函数，主要用来修饰其他函数，也就是为其他函数添加附加功能。\n\n可以让其他函数在不增加代码的前提下增加额外功能，其返回值也是一个函数对象。\n\n原则：\n\n1. 装饰器不能修改被装饰的函数的源代码\n2. 装饰器不能修改被装饰的函数的调用方式\n\n常用于有切面需求的场景，如：插入日志、事务处理、缓存、权限校验等\n\n\n\n## Python的深拷贝和浅拷贝\n\n1. 深拷贝是将对象本身复制给另一个对象，意味着对对象的副本进行修改不会影响原对象；在Python中，使用deepcopy()函数实现\n2. 浅拷贝是将对象的引用复制给另一个对象，则对对象的副本进行修改会影响原对象；在Python中，使用copy()函数实现\n\n\n\n\n\n## Python的进程和线程理解\n\n| 进程 | Linux/Unix：fork()                             |\n| ---- | ---------------------------------------------- |\n|      | 跨平台：multiprocessing()         POOL（大量） |\n| 线程 | threading                                      |\n\nThread类中的 start()和run()方法的区别：\n\n1. 通过调用线程类的start()方法可以直接启动一个线程，是线程处于就绪状态；JVM通过调用线程类的run()方法来完成实际的业务逻辑，当run()方法结束后，此线程就会终止；\n2. 直接调用线程的run()方法，则会被当成是一个普通的函数调用，程序中仍然只有主线程这一个线程\n\n即start()方法可以异步的调用run()方法；直接调用run()方法是同步的，无法达到多线程的目的\n\n\n\n## 进程和线程的区别\n\n1. 进程是资源分配的最小单位，线程是程序执行的最小单位\n2. 进程有自己独立的地址空间，而线程是共享进程中的数据的，使用相同的地址空间；因此CPU切换一个线程的花费比进程要小很多，同时创建一个线程的开销也比进程小很多\n3. 线程之间通信更方便，同一进程下的线程共享全局变量静态变量等，而进程之间的通信需要以通信（IPC）的方式进行\n4. 多进程程序更健壮，多线程程序只要有一个死掉，整个进程就死掉了，而一个进程死掉不会对另一个进程造成影响\n\n多进程的去掉就是创建进程的代价大，操作系统能同时运行的进程数是有限的；在内存和CPU的限制下，如果进程数较多，操作系统的调度会有问题\n\n\n\n## 同步和异步\n\n所谓同步就是一个任务的完成需要依赖另外一个任务时，只有等待被依赖的任务完成后，依赖的任务才能算完成，这是一种可靠的任务序列。要么成功都成功，失败都失败，两个任务的状态可以保持一致。\n\n所谓异步是不需要等待被依赖的任务完成，只是通知被依赖的任务要完成什么工作，依赖的任务也立即执行，只要自己完成了整个任务就算完成了。至于被依赖的任务最终是否真正完成，依赖它的任务无法确定，所以它是不可靠的任务序列。","tags":["Python"],"categories":["2.Programming","Python"]},{"title":"Python中装饰器的理解","url":"/2.Programming/1.Python/Python中装饰器的理解/","content":"\n## 说明\n\n装饰器的本质是函数，主要用来修饰其他函数，也就是为其他函数添加附加功能。可以让其他函数在不增加代码的前提下增加额外功能，其返回值也是一个函数对象。常用于有切面需求的场景，如：插入日志、事务处理、缓存、权限校验等。\n\n### 参考\n\n[Python装饰器](https://blog.csdn.net/weixin_44141532/article/details/87211683?spm=1001.2014.3001.5501)\n\n[Python中的闭包](https://blog.csdn.net/weixin_44141532/article/details/87116038?spm=1001.2014.3001.5501)\n\n## 闭包\n\n### 理解\n\n我们可以将闭包理解为一种特殊的函数，这种函数由两个函数的嵌套组成，且称之为外函数和内函数，外函数返回值是内函数的引用，此时就构成了闭包。\n\n### 格式\n\n```python\ndef 外层函数(参数):\n    def 内层函数():\n        print(\"内层函数执行\", 参数)\n    return 内层函数\n\n内层函数的引用 = 外层函数(\"传入参数\")\n内层函数的引用()\n```\n\n外层函数中的参数，不一定要有，据情况而定，但是一般情况下都会有并在内函数中使用到。\n\n### 案例\n\n```python\ndef func(a, b):\n    def line(x):\n        return a * x - b\n    return line\n\nline = func(2, 3)\nprint(line(5))\n```\n\n结果得到 7\n在这个案例中，外函数func有接收参数 a=2，b=3，内函数line接收参数x=5，在内函数体中计算了a*x-b 即 2×5-3的值作为返回值，外函数返回内函数的引用，这里的引用指的是内函数line在内存中的起始地址，最终调用内函数line()得到返回值7\n\n### 内函数中修改外函数的值\n\n一般在函数结束时，会释放临时变量，但在闭包中，由于外函数的临时变量在内函数中用到，此时外函数会把临时变量与内函数绑定到一起，这样虽然外函数结束了，但调用内函数时依旧能够使用临时变量，即闭包外层的参数可以在内存中进行保留\n如果想要在内函数中修改外函数的值，需要使用 nonlocal 关键字声明变量\n\n```python\ndef func(a, b):\n    def line(x):\n        nonlocal a\n        a = 3\n        return a * x - b\n    return line\n\nline = func(2, 3)\nprint(line(5))\n```\n\n此时运行结果为：12\n\n## 装饰器\n\n### 装包/拆包\n\n装包：把位置参数放到元组中，把关键字参数放到字典中\n拆包：还原到最初的数据样貌\n\n```python\ndef func1(*args, **kwargs):  # 装包\n    print(\"args:\", args)\n    print(\"kwargs:\", kwargs)\n\n    print(\"拆包:\", *args)\n    func2(**kwargs)   # **kwargs无法直接打印出来\n\ndef func2(**kwargs):   # func2(a=1)再次装包 得到字典\n    print(\"字典:\", kwargs)\n\nfunc1(1, 2, 3, a=1)\n```\n\n### 装饰器导入\n\n装饰器可以用闭包和类来实现，首先介绍使用闭包完成装饰器。\n我们装饰的函数有四种：\n\n```\n1. 无参数，无返回值\n2. 有参数，无返回值\n3. 无参数，有返回值\n4. 有参数，有返回值\n```\n\n#### 1、无参数，无返回值 ####\n\n```python\ndef func1(func):\n    def func2():  # 内函数中，完成对额外功能的添加，调用原来的函数\n        print(\"无参，无返回值\")\n        func()\n    return func2\n\n@func1\ndef test():\n    print(\"test\")\n\ntest()\n\n\n# --- 输出结果--- #\n无参，无返回值\ntest\n```\n\n#### 2、有参数，无返回值\n\n```python\ndef func1(func):\n    def func2(args):\n        print(\"有参，无返回\")\n        func(args)  # 返回用户传的参数\n    return func2\n\n@func1\ndef test(args):\n    print(args)\n\ntest(123)\n\n# --- 输出结果--- #\n有参，无返回\n123\n```\n\n#### 3、无参数，有返回值\n\n```python\ndef func1(func):\n    def func2():\n        print(\"无参，有返回值\")\n        return func()  # return返回函数的返回值\n    return func2\n\n@func1\ndef test():\n    return 1\n\nprint(test())\n\n# --- 输出结果--- #\n无参，有返回值\n1\n```\n\n#### 4、有参数，有返回值\n\n```python\ndef func1(func):\n    def func2(args):\n        print(\"有参，有返回\")\n        return func(args)\n    return func2\n\n@func1\ndef test(args):\n    return args\n\nprint(test(45))\n\n# --- 输出结果--- #\n有参，有返回\n45\n```\n\n#### 5、参数不定长\n\n```python\ndef set_fun(func):\n    def call_fun(*args, **kwargs):\n        print(\"添加额外功能\")\n        return func(*args, **kwargs)\n    return call_fun\n\n@set_fun\ndef test(*args, **kwargs):\n    print(args)\n    print(kwargs)\n    return 100\n\n\nprint(test(1, 2, 3, m=10, n=20))\n\n# --- 输出结果--- #\n添加额外功能\n(1,2,3)\n{'n':20,'m':10}\n100\n```\n\n这种格式的装饰器，是万能的，即它适用于不同的函数（有无参数，返回值都适用）\n在上面的装饰器中，@set_fun 是Python中的一种语法糖，当程序执行到这里时，其实底层做了 test = set_fun(test) 这样的转化，所以我们的func指向test的引用，于是当我们在内函数中调用函数func时，实际上是在调用函数test，此时我们便可以做到在不更改原代码的情况下，给我们的代码添加其他的功能！\n\n### 类装饰器\n\n其实使用我们的类也可以实现装饰器的效果，当你理解了使用闭包完成装饰器时，类装饰器会非常好理解，它们的原理是相似的，只不过类有它自己的操作~\n\n```python\nclass MyObject(object):\n    def __init__(self, func):\n        self.func = func\n\n    def __call__(self, *args, **kwargs):\n        # 在这里完成额外功能的添加以及调用原函数\n        print(\"添加额外的功能\")\n        return self.func(*args, **kwargs)  # 拆包\n\n\n@MyObject  # test = MyObject(test) 创建实例对象调用魔法方法__init__\ndef test(*args, **kwargs):\n    print(\"test\", args)\n    print(\"test\", kwargs)\n\n\ntest(1, 2, 3, 4, a=3)  # 实例对象()　调用魔法方法__call__\n\n# --- 输出结果--- #\n添加额外功能\ntest(1,2,3,4)\ntest{'a':3}\n```\n\n在@MyObject时，底层同样做了转化，test = MyObject(test)，这时创建了实例对象test ，并传入参数test，所以会执行我们类中的__init__魔法方法时，此时test(1, 2, 3, 4, a=3)就等于是我们创建的实例对象test()，这时会执行我们类中的__call__方法，在__call__方法中实现我们对功能的添加，以及原函数的调用，是不是与闭包非常相似呢 ˙ ω ˙\n","tags":["Python"],"categories":["2.Programming","Python"]},{"title":"Python异步编程之asyncio","url":"/2.Programming/1.Python/Python异步编程之asyncio/","content":"\n## 同步异步概念\n\n**同步：**是指完成事务的逻辑，顺序执行。\n\n**异步：**是和同步相对的，异步是指在处理调用这个事务的之后，不会等待这个事务的处理结果，直接处理第二个事务去了，通过状态、通知、回调来通知调用者处理结果。\n\nPython中使用asyncio进行异步IO的操作。\n\n## 说明\n\n**参考：**[asyncio](https://www.liaoxuefeng.com/wiki/1016959663602400/1017970488768640) , [Python异步编程](https://www.cnblogs.com/shenh/p/9090586.html)\n\n每个线程有一个事件循环，主线程调用asyncio.get_event_loop()时会创建事件循环，你需要把异步的任务丢给这个循环的run_until_complete()方法，事件循环会安排协同程序的执行。\n\n## Python3.4实例\n\n```python\nimport asyncio\n\n@asyncio.coroutine\ndef hello():\n    print(\"Hello world!\")\n    # 异步调用asyncio.sleep(1):\n    r = yield from asyncio.sleep(1)\n    print(\"Hello again!\")\n\n# 获取EventLoop:\nloop = asyncio.get_event_loop()\n# 执行coroutine\nloop.run_until_complete(hello())\nloop.close()\n```\n\n`@asyncio.coroutine`把一个generator标记为coroutine类型，然后，我们就把这个`coroutine`扔到`EventLoop`中执行。\n\n`hello()`会首先打印出`Hello world!`，然后，`yield from`语法可以让我们方便地调用另一个`generator`。由于`asyncio.sleep()`也是一个`coroutine`，所以线程不会等待`asyncio.sleep()`，而是直接中断并执行下一个消息循环。当`asyncio.sleep()`返回时，线程就可以从`yield from`拿到返回值（此处是`None`），然后接着执行下一行语句。\n\n**异步操作需要在`coroutine`中通过`yield from`完成。**\n\n## Python3.5实例\n\n`async`和`await`是针对coroutine的新语法，要使用新的语法，只需要做两步简单的替换：\n\n1. 把`@asyncio.coroutine`替换为`async`；\n2. 把`yield from`替换为`await`。\n\n```python\nimport asyncio \n\nasync def hello():\n    print(\"Hello world!\")\n    r = await asyncio.sleep(1)\n    print(\"Hello again!\")\n    \n# 获取EventLoop:\nloop = asyncio.get_event_loop()\n# 执行coroutine\nloop.run_until_complete(hello())\nloop.close()\n```\n\n## 并发HTTP实例\n\n如果需要并发http通常是用requests，但requests是同步的库，如果想异步的话需要引入aiohttp。\n\n**这里引入一个类，from aiohttp import ClientSession，首先要建立一个session对象，然后用session对象去打开网页**。session可以进行多项操作，比如post, get, put, head等。基本用法：\n\n```python\nasync with ClientSession() as session:\n    async with session.get(url) as response:\n```\n\n**aiohttp异步实现的例子：**\n\n```python\nimport asyncio\nfrom aiohttp import ClientSession\n\ntasks = []\nurl = \"https://www.baidu.com/{}\"\nasync def hello(url):\n    async with ClientSession() as session:\n        async with session.get(url) as response:\n            response = await response.read()\n            print(response)\n\nif __name__ == '__main__':\n    loop = asyncio.get_event_loop()\n    loop.run_until_complete(hello(url))\n```\n\n首先`async def` 关键字定义了这是个异步函数，`await` 关键字加在需要等待的操作前面，`response.read()`等待`request`响应，是个耗IO操作。然后使用ClientSession类发起http请求。","tags":["Python"],"categories":["2.Programming","Python"]},{"title":"Django常用的第三方包","url":"/2.Programming/1.Python/Django常用的第三方包/","content":"\n### API开发\n\n```shell\n djangorestframework    #https://www.django-rest-framework.org/\n django-rest-multiple-models   #model层返回多个库信息\n django-cors-headers   #跨域\n```\n\n### 查询\n\n```shell\n django-filter\n django-haystack\n drf-haystack\n```\n\n### 后台界面\n\n```shell\nbootstrap_admin   #推荐\ndjango-jet\nxadmin\ndjango-simpleui\ndjango-suit\ndjango-grappelli\n```\n\n### 调试\n\n```shell\ndjango-debug-toolbar    #推荐\n```\n\n### 对象级权限\n\n```shell\ndjango-guardian\n```\n\n### 异步\n\n```shell\ncelery   \n```\n\n### 富文本编辑器\n\n```shell\ndjango-ckeditor\ndjango-tinymce\n```\n\n","tags":["Python"],"categories":["2.Programming","Python"]},{"title":"HttprunnerManager接口测试平台","url":"/2.Programming/1.Python/HttprunnerManager接口测试平台/","content":"\n## 说名\n\n部门业务成立之初，便开始使用HttpRunner进行接口自动化的维护；根据平台维护用例较通过xml维护用例的好处是可以查看当前模块对应的用例个数、负责人和历史报告等信息，且使用数据库维护，所以在业务测试空隙进行了用例迁移。\n\n## HttpRunner\n\n### 简介\n\nHttpRunner 是一款面向 HTTP(S) 协议的通用测试框架，只需编写维护一份 `YAML/JSON` 脚本，即可实现自动化测试、性能测试、线上监控、持续集成等多种测试需求。\n\n[项目地址](https://github.com/HttpRunner/HttpRunner)\n\n[中文手册]([http://cn.httprunner.org)\n\n## HttpRunnerManager\n\n### 简介\n\nHttpRunnerManager是基于`HttpRunner`的接口自动化测试平台,该工具是对 `HttpRunner`的包装和Web图形化, 另外还增加了一些新概念(项目/模块)用来组织用例。\n如果对yaml语法格式不熟悉，以及对于httprunner命令不熟悉的可以使用该平台执行接口自动化测试。\n\n[项目地址](https://github.com/HttpRunner/HttpRunnerManager)\n\n### 核心特性\n\n1. 项目管理：新增项目、列表展示及相关操作，支持用例批量上传(标准化的HttpRunner json和yaml用例脚本)\n\n2. 模块管理：为项目新增模块，用例和配置都归属于module，module和project支持同步和异步方式\n\n3. 用例管理：分为添加config与test子功能，config定义全部变量和request等相关信息 request可以为公共参数和请求头，也可定义全部变量\n\n4. 场景管理：可以动态加载可引用的用例，跨项目、跨模块，依赖用例列表支持拖拽排序和删除\n\n5. 运行方式：可单个test，单个module，单个project，也可选择多个批量运行，支持自定义测试计划，运行时可以灵活选择配置和环境\n\n6. 分布执行：单个用例和批量执行结果会直接在前端展示，模块和项目执行可选择为同步或者异步方式，\n\n7. 环境管理：可添加运行环境，运行用例时可以一键切换环境\n\n8. 报告查看：所有异步执行的用例均可在线查看报告，可自主命名，为空默认时间戳保存，\n\n9. 定时任务：可设置定时任务，遵循`crontab`表达式，可在线开启、关闭，完毕后支持邮件通知\n\n10. 持续集成：jenkins对接，开发中。。。\n\n### 环境安装\n\n**1、安装docker、mysql、rabbitmq并启动**\n\n```shell\ndocker search mysql\n\ndocker pull mysql:5.7\n\ndocker images |grep mysql\n\ndocker run -p 3306:3306 --name bj_qa_mysql -v $PWD/conf:/etc/mysql/conf.d -v $PWD/logs:/logs -v $PWD/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7\n\ndocker ps\n\nsudo docker exec -it bj_qa_mysql bash\n\nmysql -h 127.0.0.1 -u root -p   #密码123456\n\nCREATE DATABASE HttpRunner DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci;\n \n\ndocker search rabbitMq\n\ndocker pull rabbitmq:3.7-management\n\ndocker run -d --name rabbitmq -e RABBITMQ_DEFAULT_USER=user -e RABBITMQ_DEFAULT_PASS=password -p 15672:15672 -p 5672:5672 rabbitmq:3.7-management\n\ncd /var/lib/docker\n\nsudo docker exec -it rabbitmq bash\n\nrabbitmqctl add_user admin 123456\n\nrabbitmqctl set_permissions -p / admin '.*' '.*' '.*'\n```\n\n**2、安装git，拉取代码**\n\n```shell\ngit clone https://github.com/HttpRunner/HttpRunnerManager.git\n```\n\n**3、修改配置**\n\n-    修改:HttpRunnerManager/HttpRunnerManager/settings.py里DATABASES字典和邮件发送账号相关配置\n\n```\n     DATABASES = {\n         'default': {\n         'ENGINE': 'django.db.backends.mysql',\n         'NAME': 'HttpRunner',  # 新建数据库名\n         'USER': 'root',  # 数据库登录名\n         'PASSWORD': 'lcc123456',  # 数据库登录密码\n         'HOST': '127.0.0.1',  # 数据库所在服务器ip地址\n         'PORT': '3306',  # 监听端口 默认3306即可\n     }\n }\n\n EMAIL_SEND_USERNAME = 'username@163.com'  # 定时任务报告发送邮箱，支持163,qq,sina,企业qq邮箱等，注意需要开通smtp服务\n EMAIL_SEND_PASSWORD = 'password'     # 邮箱密码\n```\n\n-    修改:HttpRunnerManager/HttpRunnerManager/settings.py里worker相关配置\n\n```shell\n    djcelery.setup_loader()\n    CELERY_ENABLE_UTC = True\n    CELERY_TIMEZONE = 'Asia/Shanghai'\n    BROKER_URL = 'amqp://guest:guest@127.0.0.1:5672//'  # 127.0.0.1即为rabbitmq-server所在服务器ip地址\n    CELERYBEAT_SCHEDULER = 'djcelery.schedulers.DatabaseScheduler'\n    CELERY_RESULT_BACKEND = 'djcelery.backends.database:DatabaseBackend'\n    CELERY_ACCEPT_CONTENT = ['application/json']\n    CELERY_TASK_SERIALIZER = 'json'\n    CELERY_RESULT_SERIALIZER = 'json'\n\n    CELERY_TASK_RESULT_EXPIRES = 7200  # celery任务执行结果的超时时间，\n    CELERYD_CONCURRENCY = 10  # celery worker的并发数 也是命令行-c指定的数目 根据服务器配置实际更改 默认10\n    CELERYD_MAX_TASKS_PER_CHILD = 100  # 每个worker执行了多少任务就会死掉，我建议数量可以大一些，默认100\n\n\n4、执行pip install -r requirements.txt 安装工程所依赖的库文件\n5、切换到HttpRunnerManager目录(cd /home/HttpRunnerManager) 生成数据库迁移脚本,并生成表结构\n    python manage.py makemigrations ApiManager #生成数据迁移脚本\n    python manage.py migrate  #应用到db生成数据表\n\n\n6、创建超级用户，用户后台管理数据库，并按提示输入相应用户名，密码，邮箱。 如不需用，可跳过此步骤\n    python manage.py createsuperuser\n7、启动服务\n    python manage.py runserver \n    python manage.py runserver &          &作用：回到linux控制台服务不会停掉\n\n   \n8、访问并使用\n\n浏览器输入：http://192.168.3.143:8000/api/register/ 注册用户，开始尽情享用平台\n\n浏览器输入：http://192.168.3.143:8000/admin/ 输入步骤6设置的用户名、密码，登录后台运维管理系统，可后台管理数据\n```\n\n## 异步生成测试报告\n\n**1、RebbitMQ信息**\n\n```shell\n浏览器输入：http://192.168.3.143:15672 默认的登陆账号为：guest，密码为：guest \n```\n\n**2、进入到HttpRunnerManager目录，启动worker**\n\n```shell\npython manage.py celery -A HttpRunnerManager worker --loglevel=info\n```\n\n**3、启动任务监控后台**\n\n```shell\ncelery flower\n```\n\n","tags":["接口","Python"],"categories":["2.Programming","Python"]},{"title":"Jenkins更新主题","url":"/4.ToolsNotes/Jenkins/Jenkins更新主题/","content":"\n## 选择主题\n主题制作网站 jenkins-material-theme\n\n**1、选择主题颜色**\n可以选择自己喜欢的任何颜色,这里紫色只做演示\n\n![color](/images/20200910-1.png)\n\n**2、上传logo**\n\n要求png格式图片,最小高度40px\n\n![color](/images/20200910-2.png)\n\n**3、下载主题**\n\n上传好logo后就可以下载插件主题\n\n1. 下载的主题文件名为: `jenkins-material-theme.css`\n\n![color](/images/20200910-3.png)\n\n**4、配置css文件**\n\n在Jenkins安装路径的userContent目录下新建layout文件夹\n\n1. 将`jenkins-material-theme.css`文件复制到该目录下\n2. 在该目录下新建title.css文件,其中修改代码里面的content就可以改变Jenkins的Title\n\n![color](/images/20200910-4.png)\n\n```css\n#title.css内容如下：\n\n#jenkins-name-icon {\n    display: none;\n}\n\n.logo:after {\n    content: \"Jenkins of Chaos-Notebook\";\n    text-transform:none;\n    font-weight: bold;\n    font-size: 30px;\n    color: White;\n    line-height: 40px;\n    margin-left: 40px;\n}\n```\n\n## 主题插件配置\n\n**1、 安装插件**\n\n> [Simple Theme](https://plugins.jenkins.io/simple-theme-plugin/)\n\n**2、配置插件**\n\nConfigure System -> Theme, 新增两个Css Url\n\n![color](/images/20200910-5.png)\n\n添加`jenkins-material-theme.css`和`Title.css`的url\n\n1. http://localhost:8080/userContent/layout/jenkins-material-theme.css\n2. http://localhost:8080/userContent/layout/title.css\n\n![color](/images/20200910-6.png)\n\n## 新的主题\n\n查看新的主题效果\n\n**1、界面整体UI**\n\n![color](/images/20200910-7.png)","tags":["Jenkins"],"categories":["4. ToolsNotes","Jenkins"]},{"title":"Jenkins常用插件","url":"/4.ToolsNotes/Jenkins/Jenkins常用插件/","content":"\n## Timestamper\n\n```shell\nThe Timestamper plugin adds timestamps to the console output of Jenkins jobs. For example:\n\n21:51:15  Started by user anonymous\n21:51:15  Building on master\n21:51:17  Finished: SUCCESS\n```\n\n**使用**\n\n![timestamper](/images/20200821-1.png)\n\n## AnsiColor\n\n```shell\nThis plugin adds support for standard ANSI escape sequences, including color, to Console Output.　\n```\n\n**使用**\n\n![timestamper](/images/20200821-2.png)","tags":["Jenkins"],"categories":["4. ToolsNotes","Jenkins"]},{"title":"uWSGI启动Django项目","url":"/2.Programming/1.Python/uWSGI启动Django项目/","content":"\n\u000b\f\f\u000b![uwsgi](/images/20200811-1.png)\n\n\n####  安装\n\n```\n pip install uwsgi\n```\n\n\n\n**新增文件uwsgi.ini；跟manage.py 同一级目录**\n\n```\n 1 [uwsgi]\n 2 ; 监听的端口\n 3 http = :8000\n 4 \n 5 ; 指定和nginx进行套接字通信的方式：端口或文件\n 6 ; socket = 127.0.0.1:8001\n 7 ; socket = /home/kzzf/project/OfferHelp/OfferHelp.sock\n 8 \n 9 ; 项目所在目录，和manage.py同级\n10 chdir = /home/kzzf/project/OfferHelp\n11 \n12 ; 虚拟环境所在目录\n13 home=/home/kzzf/env/OfferHelp-env\n14 PYTHONHOME = /home/kzzf/env/OfferHelp-env/bin/\n15 \n16 ; 主应用中的wsgi文件\n17 wsgi-file = OfferHelp/wsgi.py\n18 \n19 ; 使用路由代理静态资源，但失败了\n20 ; static-safe=/home/kzzf/project/OfferHelp/static/\n21 ; route = /static/(.*) static:/home/kzzf/project/OfferHelp/static/$1\n22 \n23 ; 代理静态资源：路径映射\n24 static-map = /static=/home/kzzf/project/OfferHelp/collect_static\n25 \n26 ; 启动一个master进程，来管理其余的子进程\n27 master=True\n28 processes = 4\n29 threads = 2\n30 \n31 ; 保存主进程的pid，用来控制uwsgi服务\n32 pidfile=/home/kzzf/project/OfferHelp/uwsgi.pid\n33 ; 启动项目  uwsgi uwsgi.ini\n34 ; uwsgi --stop/reload xxx.pid  停止/重启uwsgi\n35 \n36 ; 设置后台运行，保存日志\n37 daemonize=/home/kzzf/project/OfferHelp/log/uwsgi.log\n38 ; deamonize=1  ; 用来配置background运行\n39 \n40 ; 设置每个工作进程处理请求的上限，达到上限时，将回收（重启）该进程。可以预防内存泄漏\n41 max-requests=5000\n42 \n43 # 服务停止时自动移除unix Socket和pid文件\n44 vacuum=true\n```\n\n\n\n#### 启动项目\n\n```\n1 uwsgi uwsgi.ini\n2 \n3 # 停止\n4 uwsgi --stop uwsgi.pid\n5 pkill -f uwsgi -9\n```","tags":["接口","Python"],"categories":["2.Programming","Python"]},{"title":"解决pip install太慢的问题","url":"/2.Programming/1.Python/解决pip install太慢的问题/","content":"\n将pip的源换为国内的。\n\n1.新建目录及文件～/.pip/pip.conf\n\n2.内容为：\n\n[global]\nindex-url = https://pypi.tuna.tsinghua.edu.cn/simple\n\n[install]\ntrusted-host=mirrors.aliyun.com","tags":["Tool","Python"],"categories":["2.Programming","Python"]},{"title":"CentOS7.X更新yum源","url":"/4.ToolsNotes/Others/CentOS7.X更新yum源/","content":"\n#### 备份原来的yum源\n\n```\n$sudo cp /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo-backup\n```\n\n#### 设置aliyun的yum源\n\n```\n$sudo wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo\n```\n\n#### 添加EPEL源\n\n```\n$sudo wget -P /etc/yum.repos.d/ http://mirrors.aliyun.com/repo/epel-7.repo\n```\n\n#### 清理缓存，生成新缓存，执行yum系统更新\n\n```\n$sudo yum clean all\n\n$sudo yum makecache\n\n$sudo yum update（可选）\n```\n\n","tags":["Tool"],"categories":["4. ToolsNotes","Tool"]},{"title":"Harbor安装及使用","url":"/4.ToolsNotes/Docker/Harbor安装及使用/","content":"\n#### Harbor简介\n\nHarbor是一个用于存储和分发Docker镜像的企业级私有Registry服务器。\n\n#### Harbor安装\n\n##### 选择Harbor版本\n\n官网地址：https://github.com/goharbor/harbor/releases\n\n下载harbor-online-installer-v1.7.5.tgz\n\n![harbot](/images/20200214-1.png)\n\n##### 下载软件\n\n```shell\ncd /data/harbor/\n\nwget https://storage.googleapis.com/harbor-releases/release-1.7.0/harbor-online-installer-v1.7.5.tgz\n\nsudo tar xf harbor-online-installer-v1.7.5.tgz\n```\n\n##### 开始安装\n\n```shell\n[root@qa02v harbor]# [root@qa02v harbor]# \n<code class=\"hljs coffeescript\">docker-compose pull</code>\n\n[root@qa02v harbor]# [root@qa02v harbor]# ./install.sh\n总用量 1588\ndrwxr-xr-x 4 root root      35 1月  20 12:16 common\n-rw-r--r-- 1 root root     727 11月  9 2018 docker-compose.chartmuseum.yml\n-rw-r--r-- 1 root root     777 11月  9 2018 docker-compose.clair.yml\n-rw-r--r-- 1 root root    1258 11月  9 2018 docker-compose.notary.yml\n-rw-r--r-- 1 root root    3591 1月  20 12:35 docker-compose.yml\ndrwxr-xr-x 3 root root     131 11月  9 2018 ha\n-rw-r--r-- 1 root root    7908 1月  20 12:14 harbor.cfg\n-rwxr-xr-x 1 root root    6162 11月  9 2018 install.sh\n-rw-r--r-- 1 root root   10768 11月  9 2018 LICENSE\n-rw-r--r-- 1 root root     482 11月  9 2018 NOTICE\n-rw-r--r-- 1 root root 1535603 11月  9 2018 open_source_license\n-rwxr-xr-x 1 root root   39496 11月  9 2018 prepare\n```\n\n```shell\n#######################################################\nharbor.cfg               #这就是harbor的配置文件了\ninstall.sh               #安装脚本\ndocker-compose.yml       #docker-compose启动文件\n```\n\n\\#修改配置文件\n\n**# sudo vi /data/harbor/harbor.cfg**\n\n```shell\nhostname = XXX.XXX.XXX.XXX #如果端口冲突则增加端口信息 hostname = XXX.XXX.XXX.XXX:XXX\n\nharbor_admin_password = xxxxxxx （备注：密码自己设置8位，默认Harbor12345）\n```\n\n **# sudo vi docker-compose.yml**\n\n如果端口冲突，就更改端口： 80改成：8080\n\n\u000b![harbor](/images/20200214-2.png)\n\n#####  启动harbor\n\n```shell\nnulige@harbor:/nulige/tools/harbor$ sudo docker-compose up -d\nharbor-log is up-to-date\nharbor-adminserver is up-to-date\nharbor-db is up-to-date\nregistry is up-to-date\nredis is up-to-date\nregistryctl is up-to-date\nharbor-core is up-to-date\nharbor-portal is up-to-date\nharbor-jobservice is up-to-date\nRecreating nginx ...\nRecreating nginx ... done　\n```\n\n##### 登录首页\n\nhttp://XXX.XXX.XXX.XXX:XXX\n\n账号： admin\n\n密码：xxxxxxxx (自已设置的密码)\n\n##### 修改daemon.json\n\n```shell\n[root@qa02v harbor]# cat /etc/docker/daemon.json\n{\"insecure-registries\":[\"XXX.XXX.XXX.XXX:XXX\"] }\n{\n     \"credsStore\": \"pass\"\n}\n```\n\n##### 重启docker\n\n```shell\n[root@qa02v harbor]# systemctl restart docker\n```\n\n##### 登录docker\n\n```shell\ndocker login -u admin -p Harbor12345 http://XXX.XXX.XXX.XXX:XXX\n```\n\n##### 修改tag\n\n```shell\ndocker tag docker.io/jrottenberg/ffmpeg XXX.XXX.XXX.XXX:XXX/shtest/ffmpeg:v1.0\n```\n\n##### 上传镜像至Harbor\n\n```shell\ndocker push  XXX.XXX.XXX.XXX:XXX/shtest/ffmpeg:v1.0\n```\n\n##### 下载镜像至本地\n\n```shell\ndocker pull  XXX.XXX.XXX.XXX:XXX/shtest/ffmpeg:v1.0\n```\n\n\n\n#### docker login 遇到的问题\n\n```shell\nUsername: yanshinian\nPassword:\nError saving credentials: error storing credentials - err: exit status 1, out: `The user name or passphrase you entered is not correct.`\n```\n\n参考链接：https://github.com/docker/docker-credential-helpers/issues/65\n\n解决办法：rm /usr/local/bin/docker-credential-osxkeychain\n\n\n\n##### 参考资料\n\n[Docker私有仓库Harbor v1.6.1安装](https://blog.51cto.com/bigboss/2316525)[\n](https://blog.51cto.com/bigboss/2317324?source=drh)\n\n[[安装Harbor之http版本](https://www.cnblogs.com/nulige/p/10778554.html)](https://www.cnblogs.com/nulige/p/10778554.html)","tags":["Docker"],"categories":["4. ToolsNotes","Docker"]},{"title":"软件测试流程","url":"/3.Testing/Others/软件测试流程/","content":"\n说明：\n项目立项后，由产品人员、前端开发人员、服务端开发人员和测试人员组成的云管团队成立。\n提高效率的其中一个环节就是树立健全的项目流程，现就实际工作中的流程进行总结：\n\n\n\n| **产研发测流程** |                                                              |                                    |\n| ---------------- | ------------------------------------------------------------ | ---------------------------------- |\n| 1.产品为主       | 测试前准备工作                                               | 说明                               |\n|                  | 1、产品提出需求评审（与开发/测试人员确认测试范围/内容及上线时间） |                                    |\n|                  | 2、产品提供原型/需求文档等                                   |                                    |\n|                  | 3、开发确定技术方案/技术评审                                 |                                    |\n|                  | 4、测试设计case，用例评审                                    | Xmind记录检查点，Excel记录测试过程 |\n| 2.产品/开发为主  | 冒烟测试                                                     |                                    |\n|                  | 1、需求要提测，提测前RD必须严格自测                          |                                    |\n|                  | 2、需求RD进行提测（禅道），务必写清楚本次修改点及影响范围    |                                    |\n|                  | 3、提测的需求RD必须严格进行自测，保证提供的测试内容主流程正常、业务逻辑正确，测试人员更多是验证测试、异常场景测试等 |                                    |\n|                  | 4、冒烟测试通过后，进行详细测试；冒烟测试不通过，测试需求驳回 |                                    |\n| 3.测试/开发为主  | 迭代测试                                                     |                                    |\n|                  | 1、测试收到提测消息后与开发人员进行沟通，如果当前提测需求量较多，排优先级 |                                    |\n|                  | 2、Jenkins自动部署测试环境（开发修改Bug同步代码到相应分支）  |                                    |\n|                  | 3、每天沟通测试进展必要时增加测试报告；至测试结束            |                                    |\n|                  | 4、准上线环境验收测试                                        |                                    |\n| 4.开发为主       | 交付                                                         |                                    |\n|                  | 1、上线后通过标记代码分支打Tag确定上线版本                   |                                    |\n|                  | 2、上线后全体人员进行线上回归测试                            |                                    |\n|                  | 3、线上问题记录                                              |                                    |\n| 5.其他           | 总结                                                         |                                    |\n|                  | 1、bugreview                                                 |                                    |\n|                  | 2、测试总结                                                  |                                    |","tags":["总结"],"categories":["3.Testing","总结"]},{"title":"Shell增加定时任务","url":"/2.Programming/4.Shell/Shell增加定时任务/","content":"#### 增加定时任务\n\n```shell\n#CRON_FILE=\"/var/spool/cron/root\" （centos系统）\nCRON_FILE=\"/var/spool/cron/crontabs/root\"（ubantu系统）\ngrep \"cron_one_min.sh\" ${CRON_FILE}|| echo \"01 * * * * bash /data/server/cron/one_min.sh\" >> ${CRON_FILE}\n```\n\n#### 查看定时任务\n\n```shell\n#crontab -l\n```\n\n","tags":["Shell"],"categories":["2.Programming","Shell"]},{"title":"关系型数据库和非关系型数据及其区别","url":"/2.Programming/3.MySQL/关系型数据库和非关系型数据及其区别/","content":"\n[原文参考](https://www.cnblogs.com/aaronthon/p/9459353.html)\n\n## 关系型数据库\n\u000b![mysql](/images/20200107-1.png)\n\n关系型数据库最典型的数据结构是表，由二维表及其之间的联系所组成的一个数据组织\n\n| 优点 | 1、易于维护：都是使用表结构，格式一致；                      |\n| ---- | ------------------------------------------------------------ |\n|      | 2、使用方便：SQL语言通用，可用于复杂查询；                   |\n|      | 3、复杂操作：支持SQL，可用于一个表以及多个表之间非常复杂的查询。 |\n| 缺点 | 1、读写性能比较差，尤其是海量数据的高效率读写；              |\n|      | 2、固定的表结构，灵活度稍欠；                                |\n|      | 3、高并发读写需求，传统关系型数据库来说，硬盘I/O是一个很大的瓶颈。 |\n\n## 非关系型数据库\n\n\u000b![mysql](/images/20200107-2.png)\n\n非关系型数据库严格上不是一种数据库，应该是一种数据结构化存储方法的集合，可以是文档或者键值对等。\n\n| 优点 | 1、格式灵活：存储数据的格式可以是key,value形式、文档形式、图片形式等等，文档形式、图片形式等等，使用灵活，应用场景广泛，而关系型数据库则只支持基础类型。 |\n| ---- | ------------------------------------------------------------ |\n|      | 2、速度快：nosql可以使用硬盘或者随机存储器作为载体，而关系型数据库只能使用硬盘； |\n|      | 3、高扩展性；                                                |\n|      | 4、成本低：nosql数据库部署简单，基本都是开源软件。           |\n| 缺点 | 1、不提供sql支持，学习和使用成本较高；                       |\n|      | 2、无事务处理；                                              |\n|      | 3、数据结构相对复杂，复杂查询方面稍欠。                      |\n|      | 非关系型数据库的分类和比较：<br/>1、文档型<br/>2、key-value型<br/>3、列式数据库<br/>4、图形数据库 |\n\n\n\n\u000b![mysql](/images/20200107-3.png)\n\n\u000b![mysql](/images/20200107-4.png)\n\n\u000b![mysql](/images/20200107-5.png)\n\n\u000b![mysql](/images/20200107-6.png)\n\n\n\n\n\n","tags":["MySQL"],"categories":["2.Programming","MySQL"]},{"title":"Linux增加开机自启动脚本","url":"/2.Programming/4.Shell/Linux增加开机自启动脚本/","content":"### 在rc.local脚本中添加开机自启动程序\n\n![shell](/images/20191226-1.png)\n\n\n![shell](/images/20191226-2.png)","tags":["Shell"],"categories":["2.Programming","Shell"]},{"title":"Jenkins自动杀掉衍生程序","url":"/4.ToolsNotes/Jenkins/Jenkins自动杀掉衍生程序/","content":"\n在执行 shell输入框中加入`BUILD_ID=dontKillMe` ，即可防止jenkins杀死启动的进程\n\n```shell\nexport BUILD_ID=dontKillMe\nPROJECT_LOCATION=\"/usr/local/project/\"\nHOST=$HOST\n\nrsync -avz --delete --progress --exclude \"config*\" --exclude \"db\" ${WORKSPACE}/  root@${HOST}:$PROJECT_LOCATION\n \nssh -tt root@${HOST}  \"    \n     cd $PROJECT_LOCATION\n     nohup ./server >server.log 2>&1 &\n     sleep 10\n     exit     \n\"\n```\n\n","tags":["Jenkins"],"categories":["4. ToolsNotes","Jenkins"]},{"title":"Docker配置参数详解---/etc/docker/daemon.json完整参数","url":"/4.ToolsNotes/Docker/Dcoker配置参数详解/","content":"\n## Docker配置参数详解\n**实际配置的参数**\n\n```shell\n{\"insecure-registries\":[\"XXX.XXX.XXX.XXX:XXX\"] }\n{ \n     \"credsStore\": \"pass\"\n}\n```\n\n\n\n**全部参数**\n\n\n```shell\n{\n“api-cors-header”:\"\", ——————在引擎API中设置CORS标头\n“authorization-plugins”:[], ——————要加载的授权插件\n“bridge”:\"\", ————将容器附加到网桥\n“cgroup-parent”:\"\", ——————为所有容器设置父cgroup\n“cluster-store”:\"\", ——————分布式存储后端的URL\n“cluster-store-opts”:{}, ————————设置集群存储选项（默认map []）\n“cluster-advertise”:\"\", ————————要通告的地址或接口名称\n“debug”: true, ————————启用调试模式，启用后，可以看到很多的启动信息。默认false\n“default-gateway”:\"\", ——————容器默认网关IPv4地址\n“default-gateway-v6”:\"\", ——————容器默认网关IPv6地址\n“default-runtime”:“runc”, ————————容器的默认OCI运行时（默认为“ runc”）\n“default-ulimits”:{}, ——————容器的默认ulimit（默认[]）\n“dns”: [“192.168.1.1”], ——————设定容器DNS的地址，在容器的 /etc/resolv.conf文件中可查看。\n“dns-opts”: [], ————————容器 /etc/resolv.conf 文件，其他设置\n“dns-search”: [], ————————设定容器的搜索域，当设定搜索域为 .example.com 时，在搜索一个名为 host 的 主机时，DNS不仅搜索host，还会搜\n索host.example.com 。 注意：如果不设置， Docker 会默认用主机上的 /etc/resolv.conf 来配置容器。\n“exec-opts”: [], ————————运行时执行选项\n“exec-root”:\"\", ————————执行状态文件的根目录（默认为’/var/run/docker‘）\n“fixed-cidr”:\"\", ————————固定IP的IPv4子网\n“fixed-cidr-v6”:\"\", ————————固定IP的IPv6子网\n“data-root”:\"/var/lib/docker\", ————-Docker运行时使用的根路径，默认/var/lib/docker\n“group”: “”, ——————UNIX套接字的组（默认为“docker”）\n“hosts”: [], ——————设置容器hosts\n“icc”: false, ——————启用容器间通信（默认为true）\n“ip”:“0.0.0.0”, ————————绑定容器端口时的默认IP（默认0.0.0.0）\n“iptables”: false, ———————启用iptables规则添加（默认为true）\n“ipv6”: false, ——————启用IPv6网络\n“ip-forward”: false, ————————默认true, 启用 net.ipv4.ip_forward ,进入容器后使用 sysctl -a | grepnet.ipv4.ip_forward 查看\n“ip-masq”:false, ——————启用IP伪装（默认为true）\n“labels”:[“nodeName=node-121”], ————————docker主机的标签，很实用的功能,例如定义：–label nodeName=host-121\n“live-restore”: true, ——————在容器仍在运行时启用docker的实时还原\n“log-driver”:\"\", ——————容器日志的默认驱动程序（默认为“ json-file”）\n“log-level”:\"\", ——————设置日志记录级别（“调试”，“信息”，“警告”，“错误”，“致命”）（默认为“信息”）\n“max-concurrent-downloads”:3, ——————设置每个请求的最大并发下载量（默认为3）\n“max-concurrent-uploads”:5, ——————设置每次推送的最大同时上传数（默认为5）\n“mtu”: 0, ——————设置容器网络MTU\n“oom-score-adjust”:-500, ——————设置守护程序的oom_score_adj（默认值为-500）\n“pidfile”: “”, ——————Docker守护进程的PID文件\n“raw-logs”: false, ——————全时间戳机制\n“selinux-enabled”: false, ——————默认 false，启用selinux支持\n“storage-driver”:\"\", ——————要使用的存储驱动程序\n“swarm-default-advertise-addr”:\"\", ——————设置默认地址或群集广告地址的接口\n“tls”: true, ————————默认 false, 启动TLS认证开关\n“tlscacert”: “”, ——————默认 ~/.docker/ca.pem，通过CA认证过的的certificate文件路径\n“tlscert”: “”, ————————默认 ~/.docker/cert.pem ，TLS的certificate文件路径\n“tlskey”: “”, ————————默认~/.docker/key.pem，TLS的key文件路径\n“tlsverify”: true, ————————默认false，使用TLS并做后台进程与客户端通讯的验证\n“userland-proxy”:false, ——————使用userland代理进行环回流量（默认为true）\n“userns-remap”:\"\", ————————用户名称空间的用户/组设置\n“bip”:“192.168.88.0/22”, ——————————指定网桥IP\n“registry-mirrors”: [“https://192.498.89.232:89”], ————————设置镜像加速\n“insecure-registries”: [“120.123.122.123:12312”], ———————设置私有仓库地址可以设为http\n“storage-opts”: [\n“overlay2.override_kernel_check=true”,\n“overlay2.size=15G”\n], ————————存储驱动程序选项\n“log-opts”: {\n“max-file”: “3”,\n“max-size”: “10m”,\n}, ————————容器默认日志驱动程序选项\n“iptables”: false ————————启用iptables规则添加（默认为true）\n}\n```\n\n","tags":["Docker"],"categories":["4. ToolsNotes","Docker"]},{"title":"docker-compose 管理docker的多容器配置","url":"/4.ToolsNotes/Docker/docker-compose 管理docker的多容器配置/","content":"\n```shell\nversion: '3.4'\nx-defaults: &defaults\n  restart: unless-stopped#启动模式，当值为always时，容器总是重新启动；当值为no-failure时，即出现报错容器退出时，容器重新启动；unless-stopped为容器自启模式\n  network_mode: \"host\"\nservices:\n  mysql: #服务名\n    hostname: mysql   #主机名\n    image: mysql/mysql:latest  #镜像\n    container_name: mysql  #容器名称\n    environment:\n     - TZ=Asia/Shanghai #时区\n    ports:  #端口\n      - 80:80\n      - 3000:3000\n    volumes:\n      - \"/etc/localtime:/etc/localtime:ro\" # 设置容器时区与宿主机保持一致\n      - /home/用户名/mysql/data:/data\n```\n\n","tags":["Docker"],"categories":["4. ToolsNotes","Docker"]},{"title":"Python-Jenkins信息","url":"/2.Programming/1.Python/Python-Jenkins信息/","content":"\n[1、官方文档](https://python-jenkins.readthedocs.io/en/latest/examples.html#example-1-get-version-of-jenkins)\n\n\n\n[2、Python-jenkins-api](https://www.jianshu.com/p/8fda9e96addd)\n\n \n\n[3、Python调用Jenkins](https://www.cnblogs.com/znicy/p/5498609.html)\n\n \n\n[4、Jenkins常用rest-api](https://juejin.im/post/5c70de3b6fb9a049c2330e2d)\n\n \n\n[5、Python-jenkins模块之job相关操作](https://blog.csdn.net/seeeees/article/details/79388684)\n\n","tags":["Jenkins","Python"],"categories":["2.Programming","Python"]},{"title":"通过Python调用Jenkins 常用api操作","url":"/2.Programming/1.Python/通过Python调用Jenkins常用api操作/","content":"\n[原文参考](https://www.cnblogs.com/L-O-N/p/11608220.html)\n\n```python\n# -*- coding: utf-8 -*-\n\nimport jenkins\n\n\nclass TestJenkins(object):\n    def __new__(cls, *args, **kwargs):\n        server = 'http://1.1.1.1:8080/jenkins'\n        username = 'admin'\n　　　　 # 对应用户的token信息,不是明文的密码信息\n        password = 'fljljdfladoweurojlsjdfasd123'\n        server = jenkins.Jenkins(url=server, username=username, password=password)\n        instance = super(TestJenkins, cls).__new__(cls, *args, **kwargs)\n        instance.server = server\n        return instance\n\n    def __init__(self):\n        #这里的api_token是针对远程执行任务时,jenkins要验证的token的信息\n        self.api_token = 'okfine'\n\n    def jobs_count(self):\n        print(self.server.jobs_count())\n\n    def server_info(self):\n        print(self.server.server)\n\n    def get_jobs_info(self):\n        for item in self.server.get_all_jobs():\n            print('name: %s' % item['name'], 'URL: ', item['url'])\n\n    def get_whoami(self):\n        print(self.server.get_whoami(depth=10))\n\n    def get_auth(self):\n        print(self.server.auth)\n\n    def get_debug_job_info(self, name):\n        print(self.server.debug_job_info(name))\n\n    def check_job_exists(self, name):\n        print(self.server.job_exists(name))\n\n    def get_all_jobs(self):\n        print(self.server.get_all_jobs())\n\n    def create_job(self):\n        print(self.server.create_job('API-1', jenkins.RECONFIG_XML))\n        print(self.server.create_job('API-2', jenkins.RECONFIG_XML))\n\n    def delete_job(self, name):\n        print(self.server.delete_job(name))\n\n    def copy_job(self, name, new_name):\n        print(self.server.copy_job(name, new_name))\n\n    def enable_job(self, name):\n        print(self.server.enable_job(name))\n\n    def disable_job(self, name):\n        print(self.server.disable_job(name))\n\n    def reconfig_job(self, name):\n        print(self.server.reconfig_job(name, jenkins.RECONFIG_XML))\n\n    def rename_job(self, name, new_name):\n        print(self.server.rename_job(name, new_name))\n\n    def build_job(self, name, parameters):\n        print(self.server.build_job(name, parameters, token=self.api_token))\n\n    def get_job_info(self, name):\n        # 主要是通过任务的信息,来得到需要传入的参数信息,jenkins 各种自定义选项信息,单凭肉眼是很难辨别出参数信息的,\n        # 任务相关参数信息都是在property这个参数里面\n        build_arg = self.server.get_job_info(name)[\"property\"]\n        for parameter_definitions in build_arg:\n            if len(parameter_definitions) > 1:\n                for parameter in parameter_definitions[\"parameterDefinitions\"]:\n                    print('----------------------------------')\n                    print('name: %s' % parameter[\"name\"])\n                    print('class: %s' % parameter[\"_class\"])\n                    print('type: %s' % parameter[\"type\"])\n                    print('description: %s' % parameter[\"description\"])\n                    print('jenkins_arg: %s' % parameter[\"defaultParameterValue\"][\"name\"])\n                    print('default_value: %s' % parameter[\"defaultParameterValue\"][\"value\"])\n                    if parameter[\"_class\"] == 'hudson.model.ChoiceParameterDefinition':\n                        print('can_choices: %s' % parameter[\"choices\"])\n                    print('----------------------------------')\n\n    def get_build_log(self, name):\n        last_build_number = self.server.get_job_info(name)['lastCompletedBuild']['number']\n        print('last_build_number', last_build_number)\n\n        # 查看指定构建编号的输出\n        print(self.server.get_build_console_output(name, last_build_number))\n\n    def __call__(self, *args, **kwargs):\n        self.get_job_info('shop')\n\n        # 通过特定任务的信息来得到要传入的参数信息,然后再来执行构建任务\n        # build new job, nice  operation\n        # 如下列所示的5个参数,就是此次构建必须提供的参数\n        param_dict = {'repository': 'ssh://git@xxxxx.com/xx/xxxx.git',\n                       'profile': 'xxxx-xxx',\n                       'branch': 'master',\n                       'upload_nexus': False,\n                       'deploy_app': False}\n\n        self.build_job('xxxxx', parameters=param_dict)\n\n\nTestJenkins()()\n```\n\n","tags":["Jenkins","Python"],"categories":["2.Programming","Python"]},{"title":"Django实现列表分页功能","url":"/2.Programming/1.Python/Django实现列表分页功能/","content":"\n##### 在view.py里添加分页查询方法:\n\n```python\nfrom django.http import JsonResponse\nfrom django.views.decorators.http import require_http_methods\nfrom django.core import serializers\nfrom django.core.paginator import Paginator, EmptyPage, PageNotAnInteger\nimport json\n\n# 分页查询\ndef show_page(request):\n    page = request.GET.get('page')\n    pageSize = int(request.GET.get('pageSize'))\n    response = {}\n    book_list = Book.objects.all()\n    paginator = Paginator(book_list, pageSize)\n    response['total'] = paginator.count\n    try:\n        books = paginator.page(page)\n    except PageNotAnInteger:\n        books = paginator.page(1)\n    except EmptyPage:\n        books = paginator.page(paginator.num_pages)\n    response['list'] = json.loads(serializers.serialize(\"json\", books))\n    return JsonResponse(response)\n```\n\n","tags":["接口","Python"],"categories":["2.Programming","Python"]},{"title":"教你怎么调用GitlabAPI","url":"/2.Programming/1.Python/教你怎么调用GitlabAPI/","content":"\n## **官方文档：**\n\n[参考1](https://docs.gitlab.com/ce/api/)\n\n[参考2](https://docs.gitlab.com/ee/api/branches.html#list-repository-branches)\n\n\n\n## **生成Personal Access Tokens**\n\n   选择右上角用户信息setting—>Access Tokens\n\n## **常用Gitlab API**\n\n**1、获取所有的项目信息**\n\n[private_token来自Access Tokens](http://192.168.199.184/api/v3/projects?private_token=gqv1hvjbGCLs6uAUmBV8&per_page=10)\n\n**2、获取项目信息**\n\n[15 为项目ID，来自所有的项目信息](http://192.168.199.184/api/v3/projects/15)\n\n**3、查看用户信息**\n\nhttp://192.168.199.184/api/v3/projects/15/users?private_token=gqv1hvjbGCLs6uAUmBV8&per_page=10\n\n**4、获取commits提交信息**:\n\n[15 为项目ID，来自所有的项目信息](http://192.168.199.184/api/v3/projects/15/repository/commits/master?private_token=gqv1hvjbGCLs6uAUmBV8&per_page=10)\n\n\n\n## **实战案例**\n\n**1、获取项目信息**\n\n```python\n#!/usr/bin/env python\n#-*-coding:utf-8-*-\nimport requests\nurl = 'http://192.168.199.184/api/v3/projects?private_token=oMJwN5ErC8_n1QvTsyDR&per_page=50'　　　　\nuser_url= 'http://192.168.199.184/api/v3/projects/15/users?private_token=oMJwN5ErC8_n1QvTsyDR&per_page=10'　　\n#获取项目id和项目名称\ndef GetProject_id(project_url):　　\n    r = requests.get(project_url)\n    data = r.json()\n    ProjectId_list = []\n    ProjectName_list = []\n    for i in data:\n        ProjectId_list.append(i['id'])\n        ProjectName_list.append(i['name'])\n    return ProjectId_list,ProjectName_list\n#根据项目id获取项目下的用户信息\ndef GetProject_userlist():\n    IdList = GetProject_id(url)\n    project_id = IdList[0]\n    project_name = IdList[1]\n    for id in project_id:\n        l = []\n        project_user = requests.get(user_url.format(id))　　        #生成完整的用于显示项目下所有user的连接\n        req_data = project_user.json()\n        for i in req_data:\n            l.append(i['name'])\n        print (project_name[project_id.index(id)],l)\nGetProject_userlist()\n```\n\n**2、获取项目提交信息**\n\n```python\n#-*-coding:utf-8-*-\nimport requests\nimport  re\nurl = 'http://192.168.199.184/api/v3/projects?private_token=oMJwN5ErC8_n1QvTsyDR&per_page=10'\nr =requests.get(url)\np_group = ['HJ']\ndata = r.json()\nprint (\"项目名称\",' '*20,'最近提交时间')\nfor i in data:\n    if i['ssh_url_to_repo'].split(':')[1].split('/')[0] in p_group:\n        r1 = requests.get('http://192.168.199.184/api/v3/projects/15/repository/commits/master?private_token=gqv1hvjbGCLs6uAUmBV8&per_page=10'\n            % i['id'])\n        data2 = r1.json()\n        if data2['message'].strip() == '404 Commit Not Found':\n            print (i['ssh_url_to_repo'].split(':')[1],' '*11,'未提交任何代码')\n        else:\n            print(i['ssh_url_to_repo'].split(':')[1], ' ' * 11, data2['committed_date'][:10])\n```\n\n","tags":["Git","Python"],"categories":["2.Programming","Python"]},{"title":"获取Jenkins构建时GitChangeLog","url":"/4.ToolsNotes/Jenkins/获取Jenkins构建时GitChangeLog/","content":"\n#### 参考：\n\n[获取Jenkins构建时Git Change Log](https://www.cnblogs.com/HYanqing/p/11697097.html)\n\n\n\n在基于Jenkins进行CI持续集成的工作，在构建后上传蒲公英时想将本次版本的git commit信息同步到蒲公英的下载页面。Jenkins每次构建都会根据Git 的提交记录生成一个Web页面来显示自上次构建之后的提交记录列表（如图1），但是Jenkins却并没有提供可以获取这个Strings的功能。 \n\n![images](/images/20191018-1.png)\n\n#### Maven安装\n\n  下载地址：https://maven.apache.org/download.cgi（如图）。\n\n  将下载的压缩包解压到某个目录下，例如：/Users/用户名/apache-maven-3.5.3。\n\n  在终端执行：\n\n```shell\n$ vi ~/.bash_profile\n\n$ export M2_HOME=/Users/用户名/apache-maven-3.5.3 \n\n$ export PATH=$PATH:$M2_HOME/bin\n```\n\n  最后在终端执行如下命令来使.bash_profile生效：\n\n```shell\n$ source ~/.bash_profile\n```\n\n  可以输入mvn -v来检查Maven是否生效\n\n![images](/images/20191018-2.png)\n\n#### 插件安装\n\n Jenkins里面同样有人反馈了同样的需求，有人给出了一个插件解决获取git change log的需求，插件开源地址（[https://github.com/daniel-beck/changelog-environment-plugin](https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2Fdaniel-beck%2Fchangelog-environment-plugin)）\n\n1. 因作者并没有将插件编译上传，所以我们需要将项目Clone到本地\n\n2. 然后在项目根目录下执行 *mvn verify* ，因为依赖较多，第一次build时间会比较漫长，需耐心等待\n\n3. build完成之后项目根目录中“target”文件夹中会出现“changelog-environment.hpi”这个文件\n\n（注：*mvn verify* 是Maven命令，文章最后简单说明如何安装），插件现已上传到GitHub上（[https://github.com/KrisMarko/kr-changelog](https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2FKrisMarko%2Fkr-changelog)）。\n\n#### 使用\n\n  在Jenkins的系统管理-> 管理插件-> 高级->上传插件，将刚刚编译生成的“changelog-environment.hpi”文件上传并安装到Jenkins中，安装完成后，会在“构建环境”中有“Add Changelog Information to Environment”选项，选中后会有Entry Format、File Item Format、Date Format三个可配置项，第一个就是填写提交日志输出格式的地方，采用的是Java String.format占位符的形式。其中可以使用四个参数，分别是：\n\n1. 提交的作者\n\n2. 提交的 ID\n\n3. 提交信息\n\n4. 提交时间(通过 Date Format 控制格式)\n\n  例，我在Entry Format输入 %3$s (via %1$s)\\n，然后有一条提交记录，提交信息为「fix bug」，提交者为 Kris.Marko，那么输出到环境变量的字符串就是 “fix bug (via Kris.Marko)\\n” (后面的 \\n 是为了多层转义，视使用情况请自行调整)。\n\n  通过如上设置之后，在构建时就可以在shell中来获得SCM_CHANGELOG变量来取到更新日志了。比如自动上传更新信息到内测平台（如蒲公英）。","tags":["Jenkins"],"categories":["4. ToolsNotes","Jenkins"]},{"title":"使用Shell登录远程服务器执行多条命令，SSH登录之后执行脚本文件","url":"/2.Programming/4.Shell/使用Shell登录远程服务器执行多条命令，SSH登录之后执行脚本文件/","content":"#### 参考：\n\n[使用Shell登录远程服务器执行多条命令，SSH登录之后执行脚本文件](https://blog.csdn.net/qq_36622490/article/details/100773589)\n\n这个需求主要是我在jenkins中pipeline的代码里，需要使用shell语言执行远程连接并且部署的工作，但是大多数的shell和服务器交互是使用expect解释器 就是之前我写过的那个关于expect有关的文章，问题是jenkins中默认的shell解释器只有bash，不能更改解释器的。所以就很难受，国内的百度基本都是搬运过来的内容，毫无意义，浪费时间，在国外博客浪荡几天之后终于找到了解决方案。\n\n下面我来分享一下，大致意思呢就是执行完ssh 连接远程主机之后需要执行的命令，可以进行如下操作，命令不要照抄，换成你自己的user名和ip地址。\n\n**【我在我自己电脑和服务器之间都配置了ssh免密码登录 直接使用ssh IP地址就可以登录了，强烈建议配置ssh，非常方便】**\n\n#### 登录远程主机执行单条命令\n\n登录完主机之后执行一条命令\n\n```shell\n$ ssh USER@HOST 'COMMAND'\n```\n\n获取远程主机的最新更新时间\n\n```shell\n$ ssh root@192.168.1.1 'uptime'\n```\n\n登录完远程主机就进行重启远程主机\n\n```shell\n$ ssh root@192.168.1.1 'reboot'\n```\n\n那么问题出来了，上面的都是执行一条命令，那如果我需要执行多条命令怎么办呢？之前困扰我最大的问题就是这个，执行多条命令，虽然直接堆叠多条ssh 登录的语句 那些前缀也可以，但是看着就恶心。这样我们就可以使用以下几个方案,原内容如下，我做了备注，这样比较一目了然。\n\n#### 登录远程主机执行多条命令\n\n\u000b![images](/images/20191016-1.png)\n\n 可能还有小伙伴会问，如果需要ssh登录远程之后执行指定的脚本文件怎么做？\n\n#### 登录远程主机执行指定脚本文件\n\n![images](/images/20191016-2.png)\n\n由此来看，英文还是非常重要的。不然遇到问题你都不知道怎么去搜了，不是我埋汰百度，确实国内搬运回答问题现象太严重，点进去一个除了站点不一样 内容都一样 连错别字都一样，如果你是经常和计算机打交道的一定下载个谷歌浏览器，必须可以使用谷歌，可以配置插件或者配置翻墙设备。","tags":["Shell"],"categories":["2.Programming","Shell"]},{"title":"SSH远程执行命令","url":"/2.Programming/4.Shell/SSH远程执行命令/","content":"## 参考\n\n[SSH远程执行命令](https://blog.csdn.net/liuxiao723846/article/details/82667482)\n\n\n\nSSH 是 Linux 下进行远程连接的基本工具，不光可以登录，也可以远程操作。接下来我们详细讲解一些常用的情况。\n\n## 执行简单的命令\n\n**1、查看某台主机上的磁盘使用情况**\n\n```shell\n$ ssh root@1.113.195.138 \"df -h\"\n***************************************************************************\nNOTICE TO Users\n\nThis computer system is the private property of ...\n\n***************************************************************************\n\nFilesystem Size Used Avail Use% Mounted on\n/dev/vda2 36G 3.2G 31G 10% /\ntmpfs 25G 0 25G 0% /dev/shm\n/dev/vdb 296G 2.0G 279G 1% /data\n```\n\n可以看到会把ssh远程连接的信息，以及远程执行名的返回的信息都输出到了控制台上。\n\n**2、保存远程执行命令结果**\n\n有时我们需要保存远程执行命令的结果，然后进行判断。有两种方法：\n\n```shell\n赋值的方式：result=`ssh x@B ~/command.sh`\n追加到文件：ssh root@$ip \"cmd\" >> ./log\n```\n\n详情见：https://blog.csdn.net/liuxiao723846/article/details/55045988\n\n**3、一次执行多个命令**\n\n在shell中单行语句一般要用到分号来区分代码块，多行的话用换行符来区分代码块，则无需用到分号。\n\n```shell\n$ if [ \"$PS1\" ]; then echo test is ok; fi\ntest is ok\n\n如果换做多行\n$if [ \"PS1\" ]\n> then echo \"test is ok\"\n> fi\ntest is ok\n```\n\n所以，我们可以在ssh中用分好拼接多个命令\n\n```shell\n1 ssh root@$IP \"if [ -e /lib64/libpcre.so.1 ];then echo 'file exits...';else cd /lib64 && ln -s libpcre.so.0.0.1 libpcre.so.1;fi\"\n```\n\n## 执行需要交互的命令\n\n有时候我们需要远程执行一些有交互操作的命令，如下：\n\n```sh\n$ ssh nick@xxx.xxx.xxx.xxx \"sudo ls /root\"\n$ ssh nick@xxx.xxx.xxx.xxx \"top\"\n```\n\n![images](/images/20191016-3.png)\n\n这两条命令虽然提示的失败原因不同，但它们有一个共同点：都需要与用户交互(需要 TTY)。所以它们失败的原因也是相同的：\n默认情况下，当你执行不带命令的 ssh 连接时，会为你分配一个 TTY。因为此时你应该是想要运行一个 shell 会话。\n但是当你通过 ssh 在远程主机上执行命令时，并不会为这个远程会话分配 TTY。此时 ssh 会立即退出远程主机，所以需要交互的命令也随之结束。\n好在我们可以通过 -t 参数显式的告诉 ssh，我们需要一个 TTY 远程 shell 进行交互！\n添加 -t 参数后，ssh 会保持登录状态，直到你退出需要交互的命令。\n\n## 执行本地脚本\n\n通常我们遇到的不会是上面那种简单的问题，大多数时候我们需要把若干个命令放到一个脚本里，然后分发到远程去执行。大致有两种思路：\n\n使用scp将本地脚本文件拷贝到远端，然后再通过ssh执行远端的脚本；（弊端是脚本修改后，每次都需要scp）\n直接在本地执行脚本到远程；\n一个scp的例子\n\n```shell\nfor IP in ${IP_ARR[@]}\ndo\nssh root@$IP \"rm -rf $MONITOR_TARGET_FILE\" \nssh root@$IP \"mkdir -p /data/apps/scripts\"\nscp $MONITOR_SOURCE_FILE root@$IP:$MONITOR_TARGET_FILE\nssh root@$IP 'echo \"*/1 * * * * /usr/bin/python /data/apps/scripts/checkStatus.py' $BUSINESS_TYPE '>/dev/null 2>&1\" >> /var/spool/cron/root'\n \ndone\n```\n\n重点我们在如何在本地执行脚本到远程。\n\n**1、执行一个简单的脚本到远程：**\n\n```shell\n$ cat test.sh \nls\npwd\n \n$ ssh root@10.153.195.138 < test.sh \nanaconda-ks.cfg\n/root\n```\n\n通过重定向 stdin，本地的脚本 test.sh 在远程服务器上被执行。\n\n**2、为脚本传递参数：**\n\n```shell\n$ cat test.sh \necho $1\necho $2\n \n在本地执行结构如下：\n$ sh test.sh a b\na\nb\n\n通过重定向远程执行，会报错\n$ ssh root@10.153.195.138 < test.sh a b\nbash: a: command not found\n```\n\n看来上面的方法都无法为脚本传递参数。\n要想在这种情况下(远程执行本地的脚本)执行带有参数的脚本，需要为 bash 指定 -s 参数：\n\n```shell\n$ ssh root@10.153.195.138 'bash -s' < test.sh a b\na\nb\n```\n\n除此之外，我们还可以通过替换的方式传参，然后远程执行，例如：\n\n```\ncat ./rollback_remote.sh | sed -e \"s/#module#/${MODULE_NAME}/g\" -e \"s/#runarg#/${RUN_ARG}/g\" | ssh $IP\n```\n\n## 执行远程服务器上的脚本\n\n除了执行本地的脚本，还有一种情况是脚本文件存放在远程服务器上，而我们需要远程的执行它！此时在远程服务器上用户 nick 的家目录中有一个脚本 test.sh。文件的内容如下：\n\n```shell\nls\npwd\n执行下面的命令即可（注：一定是绝对路径）：\n$ ssh nick@xxx.xxx.xxx.xxx \"/home/nick/test.sh\"\n```\n\n下面我们也尝试为脚本传递参数。在远程主机上的 test.sh 文件的末尾添加两行：\n\n```shell\necho $0\necho $1\n然后尝试执行下面的命令：\n \n$ ssh nick@xxx.xxx.xxx.xxx /home/nick/test.sh helloworld\n```\n\n可以正确得到结果。\n\n## 执行多行命令\n\n有时候我们可能需要随手写几行简单的逻辑，这也没有问题，ssh 能轻松搞定！\n\n```shell\n$ ssh root@10.153.195.138 \" \n> ls\n> pwd\n> \"\nanaconda-ks.cfg\n/root\n```\n\n你可以用单引号或双引号开头，然后写上几行命令，最后再用相同的引号来结束。\n\n当我们在命令中引用了变量时会怎么样呢？\n\n```shell\n$ name=test\n$ ssh root@10.153.195.138 \"\n> echo $name\n> \"\ntest\n\n$ ssh root@10.153.195.138 '\necho $name\n'\n```\n\n最后一行，并没有输出我们期望的 test。这里多少有些诡异，因为如果变量没有被解释的话，输出的应该是 $name 才对。但是这里却什么都没有输出。对于引用变量的写法，可以通过bash 指定了 -c 参数方式保证变量被正确解释：\n\n```shell\n$ ssh root@10.153.195.138 bash -c \"'\necho $name\n'\"\ntest\n```\n\n","tags":["Shell"],"categories":["2.Programming","Shell"]},{"title":"rsync使用","url":"/2.Programming/4.Shell/rsync使用/","content":"在使用jenkins当跳板机的场景下，有使用git pull 代码到jenkins机器后，需要将代码复制到另一台机器上，常用的复制命令有scp和rsync；现就使用到了rsync进行详解：\n\nrsync是一种快速且通用的文件复制工具，以其Delta传输算法，通过仅发送源文件和目标文件中现有文件之间的差异来减少网络发送的数据量。\n\n \n\n### 常用参数：\n\n```shell\n-z：传输时进行压缩提高效率\n-v：显示rsync过程中详细信息。可以使用\"-vvvv\"获取更详细信息\n-P：显示文件传输的进度信息\n-a --archive：归档模式，表示递归传输并保持文件属性，等同于\"-rtopgDl\"\n-r --recursive：以递归模式拷贝目录\n-R --relative：使用相对路径\n-l --links：如果文件是软链接，则拷贝软链接本身而非软链接所指向的文件\n-L --copy-links：如果文件是软链接，拷贝软链接指向的文件\n-W --whole-file：拷贝文件时不进行增量检测\n-t --times：保持 mtime 属性\n\nrsync 默认用\"quick check\"算法决定哪些文件需要增量传输。此算法只比较文件的大小和 mtime，即使其它属性不同也会认为它们是完全相同的文件，从而不需要增量传输\n建议任何时候都加上\"-t\"，否则目标文件 mtime 会设置为系统时间，导致下次更新检查出 mtime 不同而导致增量传输无效\n\n实际工作中使用-avz即可 \n```\n\n### 使用（重要）：\n\n源路径如果为目录，不带斜线表示目录本身和目录中的文件，带斜线表示目录中的文件，不包括本身\n\n```shell\n# 复制远程计算机 foo 上的 /src/bar/ 目录中的文件到本地 /data/tmp 目录中\nrsync -avz foo:/src/bar/ /data/tmp\n\n# 复制远程计算机 foo 上的 /src/bar/ 目录到本地 /data/tmp 目录中\nrsync -avz foo:/src/bar /data/tmp\n\n# 以下命令等效\nrsync -av /src/foo /dest\nrsync -av /src/foo/ /dest/foo\n```\n\n \n\n文件名（* .c）中的通配符扩展为文件列表由 shell 在运行 rsync 之前处理，而不是由 rsync 本身处理\n\n```shell\n# 复制当前路径下所有以 .c 结尾的文件至远程计算机 foo 的 /src 目录中\n# 对于远程系统上已存在的文件，会使用 rsync 远程更新协议，通过仅发送数据中的差异来更新文件\nrsync -t *.c foo:/src/\n```\n\n","tags":["Shell"],"categories":["2.Programming","Shell"]},{"title":"Jenkins-pipeline参数化显示及插件","url":"/4.ToolsNotes/Jenkins/Jenkins-pipeline参数化显示及插件/","content":"\n## Git Parameter\n\n```shell\ngitParameter branch: '',\n\nbranchFilter: '.*',  #分支过滤\n\ndefaultValue: 'master',\n\ndescription: '选择代码分支',\n\nname: 'branch',\n\nquickFilterEnabled: false,   #快速搜索\n\nselectedValue: 'NONE',\n\nsortMode: 'NONE',  #排序\n\ntagFilter: '*',   #tag过滤\n\ntype: 'PT_BRANCH' \n```\n\n\n\n## when判断\n\n[参考](https://www.cnblogs.com/zoujiaojiao/p/13219057.html)","tags":["Jenkins"],"categories":["4. ToolsNotes","Jenkins"]},{"title":"Django数据Model层总结","url":"/2.Programming/1.Python/Django数据Model层总结/","content":"\n```python\nvlaues:\n单条记录 - <class 'dict'>\n多条记录 - <class 'django.db.models.query.QuerySet'>\nvlaues_list:\n单条记录 - <class 'tuple'>\n多条记录 - <class 'django.db.models.query.QuerySet'>\n```\n\n \n\nDjango的抽象模型Models可以直接对数据库进行增删改查，不需要你自己写SQL语言来进行相关数据库操作。今天我们就以博客blog为例，看下Django是如何对数据库进行增删改查的。\n\n我们将会用到如下这个简单的Article模型: \n\n```python\nfrom django.db import models\n\nclass Article(models.Model):\n   title = models.CharField('标题', max_length=200, unique=True)\n   body = models.TextField('正文')\n\n   def __str__(self):\n       return self.title\n```\n\n \n\n## 增\n\n增即创建新的对象或添加新的条目。如果我们要给数据库添加一篇新的文章，Django提供了2种常见操作方式。\n\n**1、传统save方法**\n\n```python\nobj = Article(title=\"My first article\", body=\"My first article body\")\nobj.save()\n```\n\n注意: 该方法如果不选择save(), 创建的对象将不会保存到数据库中去。正因为如此，Django还提供了更便捷的create方法。\n\n**2、快捷的create方法**\n\n```python\nArticle.objects.create(title=\"My first article\", body=\"My first article body\")\n```\n\n注意: 对Django自带auth模块中的User模型操作，比如创建新的用户时，请用create_user方法。该方法会将密码自动加Hash存储到数据库中。\n\n```python\nfrom django.contrib.auth.models import User\nuser = User.objects.create_user(username='john',\n                                email='john@gmail.com',\n                                password='somepwd')\n```\n\n## 删\n\n删即删除一个已有对象或从表中删除一个已有条目。Django也允许同时删除多个对象或条目。\n\n**1、删除所有文章 （请慎用！！）**\n\n```python\nArticle.objects.all().delete()\n```\n\n**2、删除标题里含有python的所有文章（不区分大小写)**\n\n```python\nArticle.objects.filter(title__icontains=\"python\").delete()\n```\n\n## 改\n\n改既可以用save方法，也可以用update方法。其区别在于save方法不仅可以更新数据中现有对象数据，还可以创建新的对象。而update方法只能用于更新已有对象数据。一般来说，如果要同时更新多个对象数据，用update方法更合适。\n\n**1、利用save方法更新某一文章标题**\n\n```python\narticle = Article.objects.get(id=1)\narticle.title = \"New article title\"\narticle.save()\n```\n\n**2、利用update方法更新某一文章标题**\n\n```python\narticle = Article.objects.get(id=1).update(title='new title')\n```\n\n**3、利用update方法更新多篇文章标题**\n\n```python\narticle = Article.objects.filter(title__icontains='python').update(title='Django')\n```\n\n## 查\n\nDjango对于数据库的查询主要是get和filter等方法。我们来看几个案例。\n\n**1、查询所有数据**\n\n```python\nArticle.objects.all()\nArticle.objects.all().values()\n```\n\n\\# 只获取title列表-字典形式\n\n```python\nArticle.objects.all().values('title')\n```\n\n\\# 只获取title列表- 元组形式，只有value，没有key\n\n```python\nArticle.objects.all().values_list('title')\n```\n\n注意：使用values和values_list可以减少数据库查询工作量。如果只需要在模板中使用某些字段，而不是全部字段，建议使用values和values_list。\n\n**2、查询某一条数据**\n\n```python\nArticle.objects.get(id=1)\n```\n\n**3、模糊查询返回数据集, 并去重**\n\n```python\nArticle.objects.filter(title__icontains='python').distinct()\n```","tags":["接口","Python"],"categories":["2.Programming","Python"]},{"title":"Django三件套","url":"/2.Programming/1.Python/Django三件套/","content":"\n\n\n#### Django基础必备三件套:\n\n**1、HttpResponse 内部传入一个字符串参数，返回给浏览器**\n\n```python\nfrom django.shortcuts import HttpResponse\ndef index(request):\n    # 业务逻辑代码\n    return HttpResponse(\"OK\")\n```\n\n**2、render除request参数外还接受一个待渲染的模板文件和一个保存具体数据的字典参数。**\n\n**将数据填充进模板文件,最后把结果返回给浏览器。**　　　\n\n```python\nfrom django.shortcuts import render\ndef index(request):\n    # 业务逻辑代码\n    return render(request, \"index.html\", {\"name\": \"alex\", \"hobby\": [\"烫头\", \"泡吧\"]})\n```\n\n**3、redirect接受一个URL参数，表示跳转到指定的URL**\n\n```python\nfrom django.shortcuts import redirect\ndef index(request):\n    # 业务逻辑代码\n    return redirect(\"/home/\")\n```\n\n","tags":["接口","Python"],"categories":["2.Programming","Python"]},{"title":"Django总结","url":"/2.Programming/1.Python/Django总结/","content":"\n\n\n[centos7下部署django详细步骤](https://www.cnblogs.com/djangocn/p/9538551.html)\n\n[快速入门](https://www.cnblogs.com/zengjielin/p/8487077.html)\n\n[基础知识]([https://cnblogs.com/aylin/p/5608175.html)\n\n[日志总结](https://www.cnblogs.com/gaosai/p/10322924.html)\n\n","tags":["接口","Python"],"categories":["2.Programming","Python"]},{"title":"Django问题总结","url":"/2.Programming/1.Python/Django问题总结/","content":"\n**1、python manage.py makemigrations No changes detected**\n\n```shell\n在修改了models.py后，有些用户会喜欢用python manage.py makemigrations生成对应的py代码。\n\n但有时执行python manage.py makemigrations命令(也可能人比较皮，把migrations文件夹给删了)，会提示\"Nochangesdetected.\"可能有用的解决方式如下：\n\n先python manage.py makemigrations --empty yourappname生成一个空的initial.py\n\n再python manage.py makemigrations生成原先的model对应的migrationfile\n```\n\n \n\n**2、Django使用migrations迁移版本和数据库中报错解决方案**\n\n[参考](https://blog.csdn.net/a599174211/article/details/82795206)\n\n \n\n**3、Django-关于manage.py migrate无效的问题**\n\n[参考](https://blog.csdn.net/qq_25730711/article/details/60327344)\n\n \n\n**4、解决在vscode中用python操作数据库模型时出现的Class \"xxx\" has no 'objects' member错误提示**\n\n[参考](https://blog.csdn.net/qq_36272282/article/details/89416663)\n\n \n\n**5、关于线上部署admin后台样式没有生效的问题**\n\n```shell\n1、在settings.py尾部：\nSTATIC_ROOT  = os.path.join(BASE_DIR, 'static')#指定样式收集目录\n#或\nSTATIC_ROOT = '/www/mysite/mysite/static'  #指定样式收集目录\n\n2、收集CSS样式，在终端输入：\npython manage.py collectstatic\n运行这个命令之后，就会自动把后台CSS样式收集到/static/目录下。刷新页面就能恢复样式！\n```\n\n","tags":["接口","Python"],"categories":["2.Programming","Python"]},{"title":"Shell处理MySQL增删改查","url":"/2.Programming/4.Shell/Shell处理MySQL增删改查/","content":"这几天做一个任务，比对两个数据表中的数据，昨天用PHP写了一个版本，但考虑到有的机器没有php或者php没有编译mysql扩展，就无法使用mysql系列的函数，脚本就无效了，今天写个shell版本的，这样，在所有linux系列机器上就都可以运行了。\n\n\n\n shell操作mysql其实就是通过mysql命令通过参数去执行语句，跟其他程序里面是一样的，看看下面这个参数：\n\n```shell\n-e, --execute=name  Execute command and quit. (Disables --force and history file.)\n```\n\n因此我们可以通过mysql -e来执行语句，就像下面这样：\n\n```shell\nmysql -hlocalhost -P3306 -uroot -p123456 $test --default-character-set=utf8 -e \"select * from users\"\n```\n\n执行之后返回下面结果：\n![images](/images/20200921-1.png)\n\n\n\n### 在shell脚本中操作mysql\n\n#### 导出数据\n\n```shell\nMYSQL=\"mysql -h192.168.1.102 -uroot -p123456 --default-character-set=utf8 -A -N\"\n#这里面有两个参数，-A、-N，-A的含义是不去预读全部数据表信息，这样可以解决在数据表很多的时候卡死的问题\n#-N，很简单，Don't write column names in results，获取的数据信息省去列名称\nsql=\"select * from test.user\"\nresult=\"$($MYSQL -e \"$sql\")\"\n\ndump_data=./data.user.txt\n>$dump_data\necho -e \"$result\" > $dump_data\n#这里要额外注意，echo -e \"$result\" > $dump_data的时候一定要加上双引号，不让导出的数据会挤在一行\n\n#下面是返回的测试数据\n3       吴彦祖  32\n5       王力宏  32\n6       ab      32\n7       黄晓明  33\n8       anonymous       32\n```\n\n\n\n#### 插入数据\n\n```shell\n#先看看要导入的数据格式，三列，分别是id，名字，年龄（数据是随便捏造的），放入data.user.txt\n12 tf 23\n13 米勒 24\n14 西安电子科技大学 90\n15 西安交大 90\n16 北京大学 90\n\n#OLF_IFS=$IFS\n#IFS=\",\"\n#临时设置默认分隔符为逗号\ncat data.user.txt | while read id name age\ndo\n    sql=\"insert into test.user(id, name, age) values(${id}, '${name}', ${age});\"\n    $MYSQL -e \"$sql\"\ndone\n```\n\n \n\n输出结果:\n\n```shell\n+----+--------------------------+-----+\n| id | name                     | age |\n+----+--------------------------+-----+\n| 12 | tf                       |  23 |\n| 13 | 米勒                       |  24 |\n| 14 | 西安电子科技大学     |  90 |\n| 15 | 西安交大                 |  90 |\n| 16 | 北京大学                 |  90 |\n+----+--------------------------+-----+\n```\n\n\n\n#### 更新数据\n\n```shell\n#先看看更新数据的格式，将左边一列替换为右边一列，只有左边一列的删除，下面数据放入update.user.txt\ntf twoFile\n西安电子科技大学 西军电\n西安交大 西安交通大学\n北京大学\n\ncat update.user.txt | while read src dst\ndo\n    if [ ! -z \"${src}\" -a ! -z \"${dst}\" ]\n    then\n        sql=\"update test.user set name='${dst}' where name='${src}'\"\n    fi\n    if [ ! -z \"${src}\" -a -z \"${dst}\" ]\n    then\n        sql=\"delete from test.user where name='${src}'\"\n    fi\n    $MYSQL -e \"$sql\"\ndone\n```\n\n \n\n输出结果：\n\n```shell\n+----+--------------------------+-----+\n| id | name                     | age |\n+----+--------------------------+-----+\n| 12 | twoFile                  |  23 |\n| 13 | 米勒                       |  24 |\n| 14 | 西军电          |  90 |\n| 15 | 西安交通大学           |  90 |\n+----+--------------------------+-----+\n```\n\n\n\n#### dump数据到sql文件\n\n```shell\n#利用mysqldump这个命令可以很轻松的导出所有数据的sql语句到指定文件\n#导出root@localhost下面的exp.Opes中的所有数据到tt.sql\nmysqldump -h localhost -u root -p exp Opes > ./tt.sql\n#回车之后输入密码就可以将所有sql语句输出到tt.sql\n```\n\n#### 导入数据到mysql数据库\n\n```shell\n#设置编码，不然可能出现乱码\nmysql -hlocalhost -uroot --default-character-set=gbk -p exp< ./tt.sql\n#回车之后输入密码，导入tt.sql中的所有数据到exp数据库中\n```\n\n\n","tags":["MySQL","Shell"],"categories":["2.Programming","Shell"]},{"title":"Jenkins-pipeline资料汇总","url":"/4.ToolsNotes/Jenkins/Jenkins-pipeline资料汇总/","content":"\n[docker-compose 快速部署持续集成环境](https://www.cnblogs.com/python-diy/p/10381385.html)\n\n[Jenkins流水线语法](https://www.jenkins.io/zh/doc/book/pipeline/syntax/)\n\n[Jenkins 用户手册](https://jenkins.io/zh/doc/)\n\n[Jenkins Pipeline+Docker实现流水线自动化构建（上百个项目共用一个脚本方案）-linux运维-51CTO博客](https://blog.51cto.com/11243465/2157080?source=dra)\n\n[Git Parameter Plugin - Jenkins - Jenkins Wiki](https://wiki.jenkins.io/display/JENKINS/Git+Parameter+Plugin)\n\n[Jenkinsfile使用_w3cschool](https://www.w3cschool.cn/jenkins/jenkins-qc8a28op.html)\n\n[Gitlab+Harbor+Jenkins pipeline实现利用tag部署docker容器-三和大神-51CTO博客](https://blog.51cto.com/bigboss/2317324?source=drh)\n\n[Jenkins配置pipeline选择git分支发布 - xj90314的专栏 - CSDN博客](https://blog.csdn.net/xj90314/article/details/100074208)\n\n[Jenkins Pipeline+Maven+Gitlab持续集成构建 - xiaodai12138 - 博客园](https://www.cnblogs.com/xiaodai12138/p/9996995.html)\n\n[持续交付实践pipeline使用：项目样例 - 蒋刚毅 - 博客园](https://www.cnblogs.com/cay83/p/7537843.html)\n\n[Jenkins pipeline 语法详解 - 清风软件测试 - 博客园](https://www.cnblogs.com/111testing/p/9721424.html)\n\n[Jenkins Pipeline与Docker的集成实践 - 简书](https://www.jianshu.com/p/c3a858050c31)\n\n[Jenkins与Docker的自动化CI/CD - 程序员大本营](http://www.pianshen.com/article/4561306963/)\n\n[基于jenkins参数化构建git项目(可选择要构建的git分支) – Honway's Blog](http://linuxsogood.org/1551.html)\n\n[jenkins应用【参数化构建过程】 - 简书](https://www.jianshu.com/p/c94eb8a739f9)\n\n[Jenkins Pipeline语法（上） - 简书](https://www.jianshu.com/p/18327865a38a)\n\n[【 分类 】- jenkins - workdsz的专栏 - CSDN博客](https://blog.csdn.net/workdsz/article/category/7125153/1)\n\n \n\n问题总结：\n\n[docker registry push/pull 错误“server gave HTTP response to HTTPS client” - 李阳阳的博客 - CSDN博客](https://blog.csdn.net/a_story_donkey/article/details/85163306)\n\n","tags":["Jenkins"],"categories":["4. ToolsNotes","Jenkins"]},{"title":"Dcoker使用普通用户执行","url":"/4.ToolsNotes/Docker/Dcoker使用普通用户执行/","content":"\n\n原文：https://www.cnblogs.com/klvchen/p/9098745.html\n\n\n#### CentOS 版本 7.4，Docker 版本 docker-1.13 及以下\n\n```shell\nll /var/run/docker.sock\nsrw-rw----. 1 root root 0 May 25 14:43 /var/run/docker.sock\n\n# 添加 docker 用户组\ngroupadd docker\n\n# 把需要执行的 docker 用户添加进该组，这里是 ibaboss\ngpasswd -a ibaboss docker\n\n# 重启 docker\nsystemctl restart docker\n\nsu - ibaboss\n\n# 运行成功\ndocker ps -a \n```\n\n\n\n#### CentOS 版本 7.4，Docker 版本 docker-ce 17 及以上\n\n```shell\nll /var/run/docker.sock\n\nsrw-rw----. 1 root docker 0 May 25 14:12 /var/run/docker.sock\n\n# 添加执行 docker 命令的用户，这里为 ibaboss\nuseradd ibaboss\n\n# 把 ibaboss 用户加入 docker 组\nusermod -G docker ibaboss  \n\nsu - ibaboss\n\ndocker ps -a \n```\n\n\n\n#### 注意事项\n\n如果之前是使用 root 用户拉取的镜像，ibaboss 用户启动镜像可能会出现问题，eg：\ndocker.elastic.co/elasticsearch/elasticsearch 6.2.4\n会出现\nmktemp: failed to create directory via template '/tmp/elasticsearch.XXXXXXXX': Permission denied\n解决方案：\n使用 ibaboss 用户重新拉取镜像","tags":["Docker"],"categories":["4. ToolsNotes","Docker"]},{"title":"Linux两台服务器之间免密登录方法","url":"/2.Programming/4.Shell/Linux两台服务器之间免密登录方法/","content":"搭建集群机器192.168.0.100和192.168.0.200里，需要两台机器中间相互拷贝文件：\n\n方式一：下载192.168.0.100机器文件到本地，再将本地文件拷贝到B机器\n\n方式二：192.168.0.100#scp -r /home/test root@192.168.0.200:/home/\n\nlinux命令scp可以在两台服务器192.168.0.100和192.168.0.200之间互传文件。第一次会提示授权操作，输入yes后在输入root用户的密码，会将192.168.0.100机器的/home/test文件拷贝到192.168.0.200机器的/home下。\n\n \n\n现每次192.168.0.100和192.168.0.200之间互传文件都要输入密码比较麻烦，现介绍一种采用公钥/私钥认证的方式去掉密码登录。\n\n注意点：\n\n1.互传文件为同一登录用户root\n\n2.秘钥存放位置为当前登录用户下 #cd ~/.ssh 可查看\n\n \n\n## 创建一个ssh key\n\n```shell\n192.168.0.100机器执行如下代码：\n\n$ ssh-keygen -t rsa -C \"your_email@example.com\" -t rsa-test\n```\n\n代码中各个参数含义为：\n\n-t 指定密钥类型，默认是 rsa ，可以省略\n\n-C 设置注释文字，比如邮箱，可以忽略\n\n-f 指定密钥文件存储文件名，使用默认文件名（推荐）；那么可以看到生成的两个文件 `id_rsa` `id_rsa.pub（id_rsa这个叫私钥；id_rsa.pub这个叫公钥）`\n\n \n\n接着又会提示你输入两次密码（该密码是你push文件的时候要输入的密码，而不是github管理者的密码），\n\n当然，你也可以不输入密码，直接按回车。那么push的时候就不需要输入密码，直接提交到github上了，如：\n\n```shell\nEnter passphrase (empty for no passphrase): \n# Enter same passphrase again:\n```\n\n接下来，就会显示如下代码提示，如：\n\n```shell\nYour identification has been saved in /c/Users/you/.ssh/id_rsa.\n# Your public key has been saved in /c/Users/you/.ssh/id_rsa.pub.\n# The key fingerprint is:\n# 01:0f:f4:3b:ca:85:d6:17:a1:7d:f0:68:9d:f0:a2:db your_email@example.com\n```\n\n当你看到上面这段代码的收，那就说明，你的 SSH key 已经创建成功，你只需要添加到github的SSH key上就可以了。\n\n \n\n## 将机器192.168.0.100上的公钥发送到机器192.168.0.200的~.ssh/authorized_keys里\n\n```shell\n服务器为：192.168.0.100\n192.168.0.100# scp  /home/root/.ssh/id_rsa.pub  root@192.168.0.200：/home/root/.ssh\n服务器为：192.168.0.200\n192.168.0.200#cd ~/.ssh\n192.168.0.200#cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys\n```\n\n注意：如192.168.0.200机器的/home/root/.ssh下存在id_rsa.pub会将文件内容覆盖，因此我们可以将新公钥进行文件的追加。\n\n##  \n\n## 执行复制操作\n\n```shell\n192.168.0.100#scp  -r /home/test  root@192.168.0.200:/home/\n```\n\n如还需要密码，则在192.168.0.200服务器里的`/etc/ssh/sshd_config`文件，关键字`PubkeyAuthentication` 确保这个值是 `yes;`若这个`sshd_config`有修改，则需要重启sshd(#service sshd restart)\n\n \n\n## 权限问题\n\n```shell\n192.168.0.200服务器里查看：\n/home/root`文件夹的权限为 700,即 显示的权限应该是 `drwx------\n/home/root/.ssh`文件夹的权限也为700\n`/home/root/.ssh/authorized_keys` 文件权限为600，即，显示的权限应该是 `-rw-------\n```\n\n \n\n 完毕之后，退出服务器的登录，再使用ssh登录，你就会发现服务器不会再向你询问密码了.\n\n \n\n## 调试\n\n192.168.0.100# ssh admin@192.168.0.200 -vvv\n\n \n\n## **问题总结**\n\n```shell\n目标机器配置SSH\n\n#vi /etc/ssh/sshd_config\n//更改为下面行\nPermitRootLogin yes\n#systemctl restart sshd \n```\n\n \n\n[关于ssh无法登陆的排查思路](https://community.qingcloud.com/topic/1140/%E5%85%B3%E4%BA%8Essh%E6%97%A0%E6%B3%95%E7%99%BB%E9%99%86%E7%9A%84%E6%8E%92%E6%9F%A5%E6%80%9D%E8%B7%AF)\n\n[SSH远程登录配置文件sshd_config详解](https://blog.csdn.net/menghuanbeike/article/details/78958015 )\n\n","tags":["Shell"],"categories":["2.Programming","Shell"]},{"title":"Jenkins知识点","url":"/4.ToolsNotes/Jenkins/Jenkins知识点/","content":"\n## 凭据\n\n**1、目的**\n\n与第三方网站或应用程序进行交互，如代码仓库、云存储系统和服务等\n\n**2、操作**\n\nJenkins-凭据-系统-全局凭据\n\n**3、权限**\n\nJenkins 中保存的凭证可以用于：\n\n- 任何适用于 Jenkins 的任何地方（即全局证书）\n- 特定的 Pipeline 项目\n- 特定的 Jenkins 用户","tags":["Jenkins"],"categories":["4. ToolsNotes","Jenkins"]},{"title":"Docker上传镜像至Harbor","url":"/4.ToolsNotes/Docker/Docker上传镜像至Harbor/","content":"\n构造镜像的两种方式：1.commit 2.Dockerfile\n\n \n\nDocker提供了一个docker commit命令，可以将容器的存储层保存下来成为镜像。换句话说，就是在原有镜像的基础上，再叠加上容器的存储层，并构成新的镜像。\n\n以后我们运行这个新镜像的时候，就会拥有原有容器的最后的文件变化。\n\ndocker commit的语法格式为：\n\n```sh\ndocker commit [选项] <容器ID或容器名> [<仓库名>[:<标签>]]\n```\n\n 实例：\n\n```shell\ndocker commit -m 'Test' -a 'Tester' 14277e296feb 192.168.0.0:8888/shtest/rtmp:v2\n```\n\n-m ‘Test’ :记录本地修改的内容\n\n-a 'Tester'：指定修改的作者\n\n14277e296feb：复制的基础镜像\n\n192.168.0.0:8888/shetest/rtmp：复制后的镜像\n\nv2：复制后的镜像tag","tags":["Docker"],"categories":["4. ToolsNotes","Docker"]},{"title":"CDN简述","url":"/3.Testing/Others/CDN简述/","content":"\n## 简介\n\nCDN全称Content Delivery Network，即内容分发网络；其工作原理是在全国各地增加节点机器，当用户访问源站时，就近选择最近的缓存节点机器，从而减少访问时间，也可避免源站承受巨大压力。\n\n加速对象：利用HTTP或FTP下载方式进行下载的各类文件。\n\n## 工作原理\n\n借用阿里云官网的例子，介绍CDN的工作原理： \u0003![images](/images/20190901-1.png)\n\n从这个例子可以了解到：\n\n（1）CDN的加速资源是跟域名绑定的。\n\n（2）通过域名访问资源，首先是通过DNS分查找离用户最近的CDN节点（边缘服务器）的IP\n\n（3）通过IP访问实际资源时，如果CDN上并没有缓存资源，则会到源站请求资源，并缓存到CDN节点上，这样，用户下一次访问时，该CDN节点就会有对应资源的缓存了。\n\n## 框架\n\n实际测试工作中会将DNS（调度系统）和CDN（缓存系统）分为两个系统，现就测试CDN的过程进行简述：![images](/images/20190901-2.png)\n\n①通过Boss后台下发的配置信息至服务器的Redis中，包括内容有\"加速域名\"\"缓存文件匹配策略\"\"IP防盗链设置\"\"缓存文件缓存时长\"等常规配置；\n\n②CDN前端中主要负责业务处理，存储热点新闻事件等，存的是固态硬盘ssd盘（读取速度相对较快）；③CDN后端主要负责的是回源合并，存储相对而言不是很频繁需要访问的资源，存的是sata盘 。\n\n## 测试\n\nCDN测试内容较复杂，一方面是业务场景覆盖内容多，另一方面是完全底层测试，没有前端页面可以测试。\n\n功能测试时会使用curl命令进行请求域名和相关文件，通过日志了解缓存执行的流程，查看节点目录是否存在缓存文件等。\n\n![images](/images/20190901-3.png)\n\n观察可发现，实际发送请求的是一个加速域名，日常新功能可使用curl等接口类工具进行测试；当工作量较大时，可使用接口自动化框架进行回归验证，这里使用的是HttpRunner：\n\n学习地址：https://docs.httprunner.org/\n\n主要实现原理：通过修改Redis的参数，验证返回值和存储信息达到快速检测的目的。\n\nRedis中参数校验部分内容如下：\n\n```shell\n{\n    \"errno\": 0, // 接口错误状态码\n    \"errmsg\": \"\", // 接口错误描述信息\n    \"data\": [\n    {\n    \"version\": 142258770700001, //必须有，无默认值\n    \"id\": 12345, //必须配置，无默认值,域名ID\n    \n    \"prefix_cache_first\": false, // 前缀缓存优先,默认值false\n    \n    \"prefix_cache\": { // 前缀匹配缓存策略,不配置为null\n    \"\\/doc\": 86400,\n    \"\\/dox\\/aaa\": 86400\n    },\n    \n    \"suffix_cache\": { // 后缀匹配缓存策略,不配置为null\n    \"png\": 86400,\n    \"jpeg\": 86400\n    },\n    \n    \"full_cache\": { // 精确匹配缓存策略,在没有配置的时候为null\n    \"\\/index.html\": 86400\n    },\n    \n    \"http_code_cache\": { // 特殊状态码缓存策略，只允许填写 > 400 状态码,不需要配置时为null\n    \"404\": 300, // 最多 10 条策略\n    \"502\": 60\n    },\n    \n    \n    \"ip_filter_type\": \"black\", // IP 防盗链策略 [off|black|white]默认值off\n    \"ip_filter_list\": [\n    \"127.0.1.1\",\n    \"128.0.1.2/24\"\n    ],\n    \n    \"referer_filter_type\": \"black\", // Referer 防盗链控制 [off|black|white],默认值off\n    \"referer_filter_list\": [ //当referer_filter_type不为off时，此list必须有值，referer_filter_type为off时，可以为null\n    \"http:\\/\\/www.baidu.com\\/\",\n    \"ALLOW_EMPTY_REFERER\" // 普通防盗链列表 \"ALLOW_EMPTY_REFERER\" 表示允许空 referer\n    ],\n    \n    \"ftag_list\": { // ftag 防盗链,不配置为null\n    \"enable\": false, // 策略开关\n    \"expire\": 60000, // 使用过期验证时的过期时间，单位为秒\n    \"secret_key\": \"xxx\", // 加密的 key，值为字符串 最大长度 64\n    \"regexp\": [ // uri正则表达式，默认忽略大小写。如果配置成null表示域名下所有uri都生效\n    \"^/abc*123\" // 默认 4 条策略\n    ]，\n    \"ip_filter_list\": [ //IP白名单，默认值为null\n    \"127.0.1.1\",\n    \"128.0.1.2/24\"\n    ]\n    },\n    \n    // response_header_replace替换响应头，默认值null,为null不做处理，\n    \"response_header_replace\": [\n    {\n    // request_url即请求url的正则表达式列表，最多包含有6个正则表达式，\n    // 默认值为null(request_url:null),如果为null则对当前域名下的请求都生效\n    \"request_url\" : [\"http://abc.com/.*\", \"http://123.com/.*\",...],\n    },\n    \n    // replace_header即要替换的响应头及值,\n    // 默认值null 替换请求头：name 最长 128 个字符；\n    // value ，最长 256 个字符；\n    // 最多支持6组\n    \"replace_header\" : {\n    \"name1\": \"value1\",\n    \"name2\": \"value2\"\n    ...\n    },\n    }\n    ...\n    ],\n    \n    \n    \"purge_dir\": { // 默认值null, 目录刷新，最多 10 条策略\n    \"/1/2/3/\": 1466680047,\n    \"/a/\": 1466680047,\n    \"/b/b/b/\": 1478056899,\n    \"/1/1/\": 1478057169\n    },\n    \n}\n```\n\n","tags":["总结"],"categories":["3.Testing","总结"]},{"title":"Linux设置网络延迟丢包操作","url":"/2.Programming/4.Shell/Linux设置网络延迟丢包操作/","content":"\n## tc方式\n\n\\* 清除设备策略：tc qdisc del root dev eth2 2>/dev/null\n\\* 设置设备策略：tc qdisc add dev eth0 root netem loss 5%\n\ntc qdisc add dev eth2 root netem loss 5%\ntc qdisc add dev eth2 root netem delay 200ms\ntc qdisc add dev eth2 root netem delay 200ms loss 5%\ntc qdisc add dev eth2 root netem delay 400ms\n\n\n\n## comcast方式\n\nhttps://github.com/tylertreat/comcast\n\n\n\n## iptables方式","tags":["Shell"],"categories":["2.Programming","Shell"]},{"title":"OpenResty学习","url":"/4.ToolsNotes/Others/OpenResty学习/","content":"\n### 学习网址\n\n[1、OpenResty最佳实践](https://moonbingbing.gitbooks.io/openresty-best-practices/content/)\n\n[2、OpenResty中文官网](http://openresty.org/cn/)\n\n[3、Lua入门教程](https://www.runoob.com/lua/lua-tutorial.html)\n\n[4、Nginx中文文档](http://www.nginx.cn/doc/)\n\n","tags":["Tool"],"categories":["4. ToolsNotes","Tool"]},{"title":"Nginx配置文件","url":"/4.ToolsNotes/Others/Nginx配置文件/","content":"\n### 学习网址\n\n[nginx documentation — DevDocs](https://devdocs.io/nginx/) \n\n\n\n### 配置文件信息\n\n```nginx\nserver {\n   listen   80 ;\n   listen   [::]:80  ipv6only=on;\n   listen   443 default ssl;\n   listen   [::]:443 default ssl;\n   #listen   [::]:443 ssl ;\n   #listen   443 ssl;\n   ssl off; \n   ssl_certificate     /etc/nginx/sslkey/kcs.default.crt;\n   ssl_certificate_key /etc/nginx/sslkey/kcs.default.key;\n\n    server_name test1116.com;\n    #max_ranges 0;\n    autoindex on;\n    autoindex_exact_size off;\n    autoindex_localtime on;\n\n    error_log /var/log/nginx/error.log;\n    access_log /var/log/nginx/access.log;\n    \n　　#302跳转使用\n    location = /test302.html {\n        root html;\n        rewrite ^/(.*)$  http://127.0.0.1/a/123.mp4 redirect;\n        \n    }\n    \n    location = /index12.html {\n        root /home/root/auto_test/Report/html/;\n    }\n\n\n    location  /a/ {\n          root html;                \n          rewrite ^/(.*)$  http://127.0.0.1/b/123.mp4 redirect;\n    }\n\n　　# 配合html/php上传文件使用\n    location ~ .*\\.(php|php5)?$ {\n        fastcgi_pass   127.0.0.1:9000;\n        client_max_body_size 30m;\n    #   fastcgi_param    HTTPS on;\n        fastcgi_param HTTPS  $https if_not_empty;\n        fastcgi_param  SCRIPT_FILENAME    /etc/nginx/html$fastcgi_script_name;\n        include        fastcgi_params; \n        #include    fastcgi.conf;\n    }\n\n\n    error_page 405 =200 $uri;\n    #error_page 405 =200 @405;\n       #location @405 {\n    #    root /etc/nginx/html;\n           #root  /tmp/upload_tmp2;\n    #    proxy_method GET;\n       #} \n\n\n    #location /b {\n    #      root html;\n    #      rewrite /(.*)   http://127.0.0.1/c/yunkong.mp4 redirect;\n    # }\n\n    #location /c {\n    #       root html;\n    #       rewrite /(.*)  http://127.0.0.1/d/yunkong.mp4 redirect;\n    # }\n         \n                \n    #location /d {\n    #       root html;\n    #}\n    \n    location /refresh30.html {\n           expires 30s;\n        root html;        \n    }\n\n    location ~^/.* {\n        root /etc/nginx/html;\n        add_header 123 123;   #添加请求接口响应头信息        \n        gzip on;  #响应信息是否进行压缩\n#       gzip_types text/html text/plain application/javascript application/x-javascript text/javascript text/xml text/css;\n        #gzip_vary on;\n    }\n\n}\n```\n\n","tags":["Tool"],"categories":["4. ToolsNotes","Tool"]},{"title":"Postman设置环境变量和全局变量","url":"/3.Testing/接口测试/Postman设置环境变量和全局变量/","content":"\n## 设置环境变量\n\n### postman通过变换环境变量来快速变换环境地址\n\n![postman](/images/20190730-1.png)\n\n### 现可以将localhost:80信息添加至环境\n\n![postman](/images/20190730-2.png)\n\n### 点击确定后，在首页可看到已添加的环境变量信息及设置的变量信息\n\n![postman](/images/20190730-3.png)\n\n## 设置全局变量\n\n### 设置全局变量 \n\n进入全局变量设置页面；\n\n![postman](/images/20190730-4.png)\n\n### 设置变量值\n\nkey填`token`，value填`123456`（填具体token的值），点右下角`Save`保存全局变量。如有多个可以全部填好再保存。（全局变量值可用js获取实现）\n\n![postman](/images/20190730-5.png)\n\n### 获取变量值\n\n在`Headers`中添加一个header，key填`token`（接口自行规定），value为`{{token}}`（刚刚在global设置的key）。鼠标移动到上面，会显示具体的value值。也可以点右上角的小眼睛，看所有的全局变量。\n\n![postman](/images/20190730-6.png)\n\n### 查看日志\n\nView--Show Postman Console","tags":["接口"],"categories":["3.Testing","接口"]},{"title":"Postman常用设置全局变量的js片段","url":"/3.Testing/接口测试/Postman常用设置全局变量的js片段/","content":"\n#### Postman知识总结\n\n[API自动化利器](http://www.bayescafe.com/tools/use-postman-to-test-api-automatically.html)\n\n\n\n#### 获取环境变量内容\n\n```js\nvar ostype = pm.environment.get(\"ostype\");\n```\n\n\n\n#### 设置全局变量内容\n\n```js\npostman.setEnvironmentVariable(\"ts\",Math.floor(new Date().getTime()/1000));\n```\n\n\n\n#### auth签名\n\n```js\nvar auth = CryptoJS.SHA1(pm.environment.get(\"device_secret\"),{asString: true});\npostman.setEnvironmentVariable(\"auth\", auth);\n```\n\n\n\n#### 随机标识\n\n```js\nconst randomInt = (min, max) => Math.floor(Math.random() * (max - min + 1)) + min;  // 随机整数\nconst getRandomValue = list => list[randomInt(0, list.length - 1)];  // 随机选项\nconst chars = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'g', 'k', 'l', 'm', 'n', 'o', '1'];\nlet identifier = '';\nfor (let i = 0; i < 5; i++) {\n  identifier += getRandomValue(chars);\n}\npm.environment.set(\"identifier\", identifier);\n```\n\n\n\n#### schema校验\n\n```js\nlet json;\ntry {\n  json = JSON.parse(responseBody);\n} catch(err) {\n  tests['服务端没返回合法的JSON格式，请检查相关服务、网络或反向代理设置（以下跳过其他断言）'] = false;\n  tests[`[INFO] 返回：${responseBody}`] = true;\n  console.error(err);\n}\nif (json) {\n  const result = tv4.validateResult(json, schema);\n  console.log(result);\n  tests['JSON Schema格式正确 ' + result.error ] = result.valid;\n  } else {\n    console.error(result.error);\n    console.error(responseBody);\n}\n```\n\n","tags":["接口"],"categories":["3.Testing","接口"]},{"title":"Docker本地/容器文件互传","url":"/4.ToolsNotes/Docker/Docker本地:容器文件互传/","content":"\n#### 将容器内文件拷贝到宿主机\n\n```shell\n#docker cp <containerId>:/导出文件的位置/xxx.sql /宿主机的位置\n\n示例：\n#docker cp bf4c4fff338c:/root/rest.sql /root/\n```\n\n\n\n#### 将宿主机文件拷贝到容器内\n\n##### 查找所有容器\n\n```shell\n#docker ps a\n```\n\n![images](/images/20190717-1.png)\n\n##### 查找容器名字和容器长ID\n\n```shell\n#docker inspect -f '{{.ID}}' python\n```\n\n##### 拷贝本地文件到容器\n\n```shell\n#docker cp 本地路径 容器长ID:容器路径\n\n#docker cp /XXX/auto-post-advance.py  容器长ID:/root/auto-post-advance.py\n```\n\n \n\n","tags":["Docker"],"categories":["4. ToolsNotes","Docker"]},{"title":"HTTP基础知识","url":"/3.Testing/Others/HTTP基础知识/","content":"\n## 浏览器输入URL至相应的全过程\n\n1. 根据域名到DNS找到IP\n\n2. 根据IP建立TCP三次握手连接\n\n3. 连接成功发出http请求\n\n4. 服务器响应http请求\n\n5. 浏览器解析html代码并请求html中的静态资源（js/css）\n\n6. 关闭tcp连接（四次挥手）\n\n7. 浏览器渲染页面\n\n## 超文本传输协议（HTTP）\n\n超文本传输协议（HTTP）设计目的是保证客户端与服务器之间的通信\n\n客户端与服务端进行交互有很多中方法，最基本的有GET、POST、PUT和DELETE；一个URL地址，主要用于描述一个网络上的资源，而HTTP中的GET、POST、PUT和DELETE则对应着对这个资源的查、改、增、删操作。（对资源的增删改查操作都可以使用GET/POST完成，不需要用到PUT和DELETE）；现就对GET和POST进行详细说明：\n\n### GET方法\n\n查询字符串是在GET请求的URL中发送的；\n\n```shell\n/test/demo_form.php?name1=value1&name2=value2\n```\n\n其他：\n\n1. URL长度限制：最多2048个字符（2KB）\n2. 数据类型限制：只允许ASCII字符\n3. 安全性：较差，发送信息是URL的一部分\n4. 可见性：数据在URL中对所有人都是可见的\n5. 缓存：可被浏览器缓存\n\n### POST方法\n\n查询字符串是在POST请求的HTTP消息体中发送的；\n\n```shell\nPOST /test/demo_form.php HTTP/1.1\nHost: runoob.com\nname1=value1&name2=value2\n```\n\n其他：\n\n1. URL长度限制：无限制\n2. 数据类型限制：无限制\n3. 安全性：安全\n4. 可见性：数据不会显示在URL中\n5. 缓存：不可被浏览器缓存\n\n\n\n## 会话\n\n会话（Session）跟踪主要用来跟踪用户的整个绘画，常用的跟踪技术是Cookie和Session；Cookie通过在客户端记录信息确定用户身份，Session通过在服务端记录信息确定用户身份。\n\n1、存放位置\n\nCookie的数据存放在客户端的浏览器上，Session存放在服务器上\n\n2、安全程度\n\nCookie不是很安全，别人通过分析本地的Cookie并进行Cookie欺骗；考虑到安全应该使用Session\n\n3、性能\n\nSession会在一定时间内保存在服务器上，当访问者增多，会占用你的内容；考虑到减轻服务器性能方面，应该使用Cookie\n\n4、存储数据\n\n单个Cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个Cookie\n\n \n\n可以考虑将登陆等重要信息保存在session，其他信息如果需要可以保存在cookie中。\n\n## 常用返回码\n\n| 2XX（成功）       |                       |                                                              |\n| ----------------- | --------------------- | ------------------------------------------------------------ |\n|                   | 200（成功）           | 服务器已成功处理了请求。 通常，这表示服务器提供了请求的网页。 |\n| 3XX（重定向）     |                       |                                                              |\n|                   | 301（永久移动）       | 请求的网页已永久移动到新位置                                 |\n|                   | 302（临时移动）       | 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求 |\n| 4XX（请求错误）   | 404（未找到）         | 服务器找不到请求的网页                                       |\n| 5XX（服务器错误） |                       |                                                              |\n|                   | 500（服务器内部错误） | 服务器遇到错误，无法完成请求                                 |\n|                   | 504（网关超时）       | 服务器作为网关或代理，但是没有及时从上游服务器收到请求。     |\n\n\n\n## TCP连接的‘三次握手’\n\n比较重要的字段：\n\n1. 序号（sequence number）：Seq序号，占32位，用来标识从TCP源端向目的端发送的字节流，发起方发送数据时对此进行标记。\n\n2. 确认号（acknowledgement number）：Ack序号，占32位，只有ACK标志位为1时，确认序号字段才有效，Ack=Seq+1。\n\n3. 标志位（Flags）：共6个，即URG、ACK、PSH、RST、SYN、FIN等。具体含义如下：\n\nURG：紧急指针（urgent pointer）有效。ACK：确认序号有效。PSH：接收方应该尽快将这个报文交给应用层。RST：重置连接。SYN：发起一个新连接。FIN：释放一个连接。\n\n需要注意的是：不要将确认序号Ack与标志位中的ACK搞混了。确认方Ack=发起方Seq+1，两端配对。\n\n![images](/images/20210308-1.png)\n\n**为什么建立连接时是三次握手，断开连接时是四次回收？**\n\n建立连接时，被动方服务器结束CLOSED阶段进入握手阶段不需要任何准备，可以直接返回SYN和ACK建立连接；\n\n断开连接时，被动方服务器收到客户端释放连接的请求时并不能立即释放连接，因为还有很多数据需要处理，所以服务器先返回ACK确认报文，经过CLOSED_WAIT阶段准备好后释放连接后，才能返回FIN释放连接报文。\n\n## TCP和UDP的区别\n\nTCP使用场景：IP电话、实时视频会议等\n\nUDP使用场景：文件传输、邮件发送与接收等\n\n1. TCP是面向连接（如打电话前要先拨号建立联系）；UDP是无连接的，即发送数据前不需要建立连接\n2. TCP提供可靠的服务，通过TCP连接传送的数据无差错、不丢失、不重复，且按序到达；UDP尽最大努力交付，不保证可靠交付\n3. TCP面向字节流；UDP是面向报文的，没有阻塞控制\n4. 每一条TCP连接只能是点到点的；UDP支持1:1，1:N，N:1和N:N的交互通信\n5. TCP首部开销是20字节；UDP只有8字节\n6. TCP的逻辑通信信道是全双工的可靠信道；UDP则是不可靠信道\n\n\n\n\n\n","tags":["总结"],"categories":["3.Testing","总结"]},{"title":"PHP代码覆盖率实践","url":"/2.Programming/2.PHP/PHP代码覆盖率实践/","content":"\n\n\n## **前言**\n\n代码覆盖率作为一个指导性指标，可以一定程度上反应测试的完备程度，虽然100%覆盖的代码并不意味着100%无bug的应用，但是较高的覆盖率一般情况下也意味着更少的bug。\n\n## **实现说明**\n\n### 环境依赖\n\n1. xdebug：php插件，用于收集覆盖率信息\n2. php-code-coverage：phpunit下的一个库，用于从xdebug收集的覆盖率信息中生成覆盖率统计报告，支持xml、html等多种格式\n\n### 具体实现\n\n脚本和报告生成路径：/usr/local/project/config/coverage/prepend.php\n\n单测：http://XXX.XXX.XXX.XXX:8888/html/\n\nPCC：http://XXX.XXX.XXX.XXX:8888/report/\n\n#### 单测脚本\n\n 确认生成存在phpcov模块：php72 -m 查看（如无，则 #php72 /usr/local/bin/composer require \"phpunit/phpcov\":\"*\" -vvv）\n\n```php\n[root@dev01 /usr/local/project/honghan-api]# php72 ./vendor/bin/phpunit --coverage-html /usr/local/project/config/coverage/html/ ./tests/EventsLogicTest.php\n\n[root@dev01 /usr/local/project/honghan-api]# php72 ./vendor/bin/phpunit --coverage-html /usr/local/project/config/coverage/html/ ./tests\n```\n\n\n#### 代码全量统计\n\n**1、PCC依靠xdebug插件，主要在php.ini文件中增加xdebug相关配置：**\n\n```php\n[root@dev01 /etc/opt/remi/php72]# vim php.ini\n[Xdebug]\nzend_extension =\"/usr/lib64/php/modules/xdebug.so\"\nxdebug.collect_params=on\nxdebug.collect_return=on\nxdebug.remote_autostart=on\n;xdebug.remote_enable=off\n;xdebug.profiler_enable = off\n;xdebug.profiler_enable_trigger = off\n;xdebug.profiler_output_name = cachegrind.out.%t\n;xdebug.profiler_output_dir =\"/home/hhzl/tmp\"\n;xdebug.show_local_vars=0\n;xdebug.profiler_enable = on\n;xdebug.trace_enable_trigger=1\n;xdebug.trace_output_dir=\"/home/hhzl/tmp\"\n;xdebug.trace_output_name=trace.%R.%u\n;xdebug.coverage_enable = 1\n```\n\n**2、[root@dev01 /usr/local/project/config/coverage]# vim prepend.php  收集全量代码覆盖率脚本**\n\n```php\n[root@dev01 /usr/local/project/config/coverage]# vim prepend.php\n<?php\nrequire_once '/usr/local/project/honghan-api/vendor/autoload.php';\nuse SebastianBergmann\\CodeCoverage\\CodeCoverage;\n \n$coverage = new CodeCoverage;\n$coverage->filter()->addDirectoryToWhitelist('/usr/local/project/honghan-api/tests/');\n$coverage->filter()->addDirectoryToWhitelist('/usr/local/project/honghan-api/app/');\n$coverage->filter()->addDirectoryToWhitelist('/usr/local/project/honghan-api/public/');\n$coverage->start('<Site coverage>');#开始统计\nregister_shutdown_function('__coverage_stop',$coverage);#注册关闭方法\nfunction __coverage_stop(CodeCoverage $coverage){\n    $coverage->stop();\n     \n    ini_set('date.timezone', 'Asia/Shanghai');\n    writer = new \\SebastianBergmann\\CodeCoverage\\Report\\Html\\Facade;\n    writer->process($coverage,'/usr/local/project/config/coverage/html'.date('Y_m_d_H_i_s'));\n \n   $htmlWriter->process($coverage, '/usr/local/project/honghan-api/coverage_html/' . date('Y_m_d_H_i_s'));\n}\n```\n\n**3、index.php文件中引用**\n\n```php\n[root@dev01 /usr/local/project/honghan-api/public]# cat index.php\n<?php\nini_set('memory_limit', '1024M');\nini_set('date.timezone','Asia/Shanghai');\n$app = require __DIR__.'/../bootstrap/app.php';\n \n#require '/usr/local/project/config/coverage/prepend.php';\n \n$app->run();\n```\n\n**4、执行php72 index.php即可**\n\n```php\n[root@dev01 /usr/local/project/honghan-api/public]# php72 index.php\nLumen (5.8.4) (Laravel Components 5.8.*)\n```\n\n**5、配置nginx访问即可**\n\n\n\n## **注意**\n\n1. 执行# php72 index.php 文件的用户非apache，php-fpm的启动用户和组为apache，会存在统计数据写不到报告的情况；更新执行脚本用户或php-fpm的用户组","tags":["PHP"],"categories":["2.Programming","PHP"]},{"title":"ThinkPHP实现存储Session至Redis","url":"/2.Programming/2.PHP/ThinkPHP实现存储Session至Redis/","content":"\n## 涉及文件\n\n```php\nThinkphp\\Library\\Think\\Session\\Driver   中新建redis缓存文件：Redis.class.php\nThinkphp\\Common\\function.php   中function session($name='',$value='')   //session说明文件\n```\n\n### 配置文件\n\n```php\n//redis操作session\n'SESSION_AUTO_START'    =>  true,    // 是否自动开启Session\n'SESSION_TYPE'          => 'Redis',    //session类型\n'SESSION_PERSISTENT'    =>  1,        //是否长连接(对于php来说0和1都一样)\n'SESSION_CACHE_TIME'    =>  3000,        //连接超时时间(秒)\n'SESSION_EXPIRE'        => 0,        //session有效期(单位:秒) 0表示永久缓存\n'SESSION_PREFIX'        =>  'sses_',        //session前缀\n```\n\n### Redis.class.php文件\n\n```php\n<?php\n\nnamespace Think\\Session\\Driver;\n\n/**\n * Redis Session驱动\n * 要求安装phpredis扩展：https://github.com/nicolasff/phpredis\n * @category   Think\n * @package  Session\n * @subpackage  Driver\n * @version   TP3.2~TP3.2.1\n */\nclass Redis implements \\SessionHandlerInterface{\n\n    /**\n     * Redis句柄\n     */\n    private $handler;\n    private $get_result;\n\n    public function __construct(){\n        if ( !extension_loaded('redis') ) {\n            E(L('_NOT_SUPPERT_').':redis');\n        }\n        if(empty($options)) {\n            $options = array (\n                'host'          => C('REDIS_HOST') ? C('REDIS_HOST') : '127.0.0.1',\n                'port'          => C('REDIS_PORT') ? C('REDIS_PORT') : 6379,\n                'timeout'       => C('SESSION_CACHE_TIME') ? C('SESSION_CACHE_TIME') : false,\n                'persistent'    => C('SESSION_PERSISTENT') ? C('SESSION_PERSISTENT') : false,\n                'auth'          => C('REDIS_AUTH') ? C('REDIS_AUTH') : false,\n                'dbindex'       => C('REDIS_DBINDEX') ? C('REDIS_DBINDEX') : 0, //选择存库\n            );\n        }\n        $options['host'] = explode(',', $options['host']);\n        $options['port'] = explode(',', $options['port']);\n        $options['auth'] = explode(',', $options['auth']);\n\n        foreach ($options['host'] as $key=>$value) {\n            if (!isset($options['port'][$key])) {\n                $options['port'][$key] = $options['port'][0];\n            }\n            if (!isset($options['auth'][$key])) {\n                $options['auth'][$key] = $options['auth'][0];\n            }\n        }\n        $this->options =  $options;\n        $expire = C('SESSION_EXPIRE');\n        $this->options['expire'] =  isset($expire) ? (int)$expire : (int)ini_get('session.gc_maxlifetime');;\n        $this->options['prefix'] =  isset($options['prefix']) ?  $options['prefix']  :   C('SESSION_PREFIX');\n        $this->options['dbindex'] = isset($options['dbindex'])? $options['dbindex']  :   0;  //选择存库\n\n        $this->handler  = new \\Redis;\n\n    }\n\n    /**\n     * 连接Redis服务端\n     * @access public\n     * @param bool $is_master : 是否连接主服务器\n     */\n    public function connect($is_master = true) {\n        if ($is_master) {\n            $i = 0;\n        } else {\n            $count = count($this->options['host']);\n            if ($count == 1) {\n                $i = 0;\n            } else {\n                $i = rand(1, $count - 1);   //多个从服务器随机选择\n            }\n        }\n        $func = $this->options['persistent'] ? 'pconnect' : 'connect';\n        try {\n            if ($this->options['timeout'] === false) {\n                $result = $this->handler->$func($this->options['host'][$i], $this->options['port'][$i]);\n                if (!$result)\n                    throw new \\Think\\Exception('Redis Error', 100);\n            } else {\n                $result = $this->handler->$func($this->options['host'][$i], $this->options['port'][$i], $this->options['timeout']);\n                if (!$result)\n                    throw new \\Think\\Exception('Redis Error', 101);\n            }\n            if ($this->options['auth'][$i]) {\n                $result = $this->handler->auth($this->options['auth'][$i]);\n                if (!$result) {\n                    throw new \\Think\\Exception('Redis Error', 102);\n                }\n            }\n            //选择db存库\n            if (0 != $this->options['dbindex']) {\n                $this->handler->select($this->options['dbindex']);\n            }\n\n        } catch ( \\Exception $e ) {\n            exit('Error Message:'.$e->getMessage().'<br>Error Code:'.$e->getCode().'');\n        }\n    }\n\n    /**\n     * 打开Session\n     * @access public\n     * @param string $savePath\n     * @param mixed $sessName\n     */\n    public function open($savePath, $sessName) {\n        return true;\n    }\n\n    /**\n     * 关闭Session\n     * @access public\n     */\n    public function close() {\n        if ($this->options['persistent'] == 'pconnect') {\n            $this->handler->close();\n        }\n        return true;\n    }\n\n    /**\n     * 读取Session\n     * @access public\n     * @param string $sessID\n     */\n    public function read($sessID) {\n        $this->connect(0);\n        $this->get_result = $this->handler->get($this->options['prefix'].$sessID);\n        return $this->get_result;\n    }\n\n    /**\n     * 写入Session\n     * @access public\n     * @param string $sessID\n     * @param String $sessData\n     */\n    public function write($sessID, $sessData) {\n        if (!$sessData || $sessData == $this->get_result) {\n            return true;\n        }\n        $this->connect(1);\n        $expire  =  $this->options['expire'];\n        $sessID   =   $this->options['prefix'].$sessID;\n        if(is_int($expire) && $expire > 0) {\n            $result = $this->handler->setex($sessID, $expire, $sessData);\n            $re = $result ? 'true' : 'false';\n        }else{\n            $result = $this->handler->set($sessID, $sessData);\n            $re = $result ? 'true' : 'false';\n        }\n        return $result;\n    }\n\n    /**\n     * 删除Session\n     * @access public\n     * @param string $sessID\n     */\n    public function destroy($sessID) {\n        $this->connect(1);\n        return $this->handler->delete($this->options['prefix'].$sessID);\n    }\n\n    /**\n     * Session 垃圾回收\n     * @access public\n     * @param string $sessMaxLifeTime\n     */\n    public function gc($sessMaxLifeTime) {\n        return true;\n    }\n\n    /**\n     * 打开Session\n     * @access public\n     * @param string $savePath\n     * @param mixed $sessName\n     */\n    public function execute() {\n        session_set_save_handler(\n            array(&$this, \"open\"),\n            array(&$this, \"close\"),\n            array(&$this, \"read\"),\n            array(&$this, \"write\"),\n            array(&$this, \"destroy\"),\n            array(&$this, \"gc\")\n        );\n    }\n\n    public function __destruct() {\n        if ($this->options['persistent'] == 'pconnect') {\n            $this->handler->close();\n        }\n        session_write_close();\n    }\n\n}\n```\n\n","tags":["PHP"],"categories":["2.Programming","PHP"]},{"title":"ThinkPHP修改Redis操作类，支持选择数据库功能及添加其他方法","url":"/2.Programming/2.PHP/ThinkPHP修改Redis操作类，支持选择数据库功能及添加其他方法/","content":"\n## 版本\nThinkPHP 3.2.2\n\n**官方默认不支持选择数据库功能及，现就可选择数据库功能进行说明**\n\n1. config.php 配置文件中选择数据库 \n\n```php\n 'REDIS_DBINDEX' =>1, // 选择库信息（0~16）\n```\n\n2. Redis.class.php中修改__construct()方法\n\n```php\n'dbindex'  => C('REDIS_DBINDEX') ? C('REDIS_DBINDEX') : 0;  //选择存库\n\n$this->options['dbindex'] = isset($options['dbindex'])? $options['dbindex'] : 0;  //选择存库\n\n$this->handler->select($this->options['dbindex']);  //选择存库\n```\n\n\n\n**官方默认未实现鉴权功能，现就实现鉴权进行说明**\n\n1. config.php 配置文件中增加鉴权密码　\n\n```\n'REDIS_AUTH'=>'123456', //AUTH认证密码\n```\n\n2. Redis.class.php中修改__construct()方法\n\n```php\nif($this->options['auth']!=null){\n\n　　　$this->handler->auth($this->options['auth']); //说明有配置redis的认证配置密码 需要认证\n\n}\n```\n\n\n\n## 具体代码如下\n\n![code](/images/20180910-1.png)","tags":["PHP"],"categories":["2.Programming","PHP"]},{"title":"MySQL存储关联数组","url":"/2.Programming/3.MySQL/MySQL存储关联数组/","content":"\n关联数组：\n\n```php\n$fruits= array(\"apple\" => \"苹果\", \"banana\" => \"香蕉\",\"oriange\" => \"橘子\");\n```\n\n对于这样的数据，MySQL数据库因存储类型是无法直接写入的，那有什么办法呢？\n\n\n\n**解决方案：使用PHP自带的serialize()或者json_encode()函数序列化数据成字符串，之后从数据库里面读出来的数据还是字符串格式的，用unserialize()和json_decode()函数转换成数组就可以了**\n\n\n\n**写入数据库之前**\n\n```php\n$fruits_serialize = serialize($fruits); // 序列化成字符串\n\n$fruits_json = json_encode($fruits); // JSON编码数组成字符串\n```\n\n\n\n**读取数据库后**\n\n```php\n$fruits _restore = unserialize($fruits_serialize); // 反序列化成数组\n\n$fruits _dejson = json_decode($fruits_json, true); // JSON解码成数组\n```\n\n","tags":["MySQL"],"categories":["2.Programming","MySQL"]},{"title":"PHP之SMTP发送邮件","url":"/2.Programming/2.PHP/PHP之SMTP发送邮件/","content":"\n## 下载相关库\n\nclass.phpmailer.php和class.smtp.php至公共库\n\n## 编写公共函数\n\n```php\nfunction sendMail($param) {\n        $config = C('THINK_EMAIL');\n        vendor('PHPMailer.class#phpmailer'); //从PHPMailer目录导class.phpmailer.php类文件\n        $mail = new PHPMailer(); //PHPMailer对象\n        $mail->CharSet = $config['EMAIL_CHARSET']; //设定邮件编码，默认ISO-8859-1，如果发中文此项必须设置，否则乱码\n        $mail->IsSMTP();  // 设定使用SMTP服务\n        $mail->SMTPDebug = 0;   // 关闭SMTP调试功能\n        // 1 = errors and messages\n        // 2 = messages only\n        $mail->SMTPAuth = $config['EMAIL_SMTPAUTH'];   // 启用 SMTP 验证功能\n        $mail->Host = $config['SMTP_HOST'];  // SMTP 服务器\n        $mail->Port = $config['SMTP_PORT'];  // SMTP服务器的端口号\n        $mail->Username = $config['SMTP_USER'];  // SMTP服务器用户名\n        $mail->Password = $config['SMTP_PASS'];  // SMTP服务器密码\n        //$mail->SetFrom($config['FROM_EMAIL'], $config['FROM_NAME']);\n        $mail->SetFrom($param['mail_from'], $param['mail_name']);\n        $replyEmail = $config['REPLY_EMAIL'] ? $config['REPLY_EMAIL'] : $param['mail_from'];\n        $replyName = $config['REPLY_NAME'] ? $config['REPLY_NAME'] : $param['mail_name'];\n        $mail->AddReplyTo($replyEmail, $replyName);\n\n        if (!empty($param['to'])) {\n            foreach ($param['to'] as $to) {\n                $mail->AddAddress($to['address'], $to['name']);\n            }\n        }\n        if (!empty($param['cc'])) {\n            foreach ($param['cc'] as $cc) {\n                $mail->addCC($cc['address'], $cc['name']);\n            }\n        }\n//        if (!empty($param['bcc'])) {\n//            foreach ($param['bcc'] as $bcc) {\n//                $mail->addBCC($bcc['address'], $bcc['name']);\n//            }\n//        }\n\n        $param['body'] = $mail->WrapText($param['body'], 900);\n        $mail->Subject = $param['subject'];\n        if (!empty($param['body'])) {\n            $mail->MsgHTML($param['body']);\n            $mail->IsHTML($config['EMAIL_ISHTML']);\n            $mail->Body = $param['body'];\n        }\n\n//        if (!empty($param['attachment'])) { // 添加附件\n//            foreach ($param['attachment'] as $file) {\n//                if (is_file($file['path'])) {\n//                    $mail->AddAttachment($file['path'], $file['name']);\n//                }\n//            }\n//        }\n\n        for($i=0;$i<(count($param['attachment']));$i++){\n            $img=substr($param['attachment'][$i], strpos($param['attachment'][$i], \",\"));\n            $mail->AddStringAttachment(base64_decode($img),\"attach\".$i.\".png\",\"base64\",\"image/png\");\n\n        }\n\n        //重发机制\n        $ret['errno'] = 0;\n        $ret['msg'] = '';\n        if ($mail->Send()) {\n            return $ret;\n        } else {\n            if ($mail->Send()) {\n                return $ret;\n            } else {\n                $ret['errno'] = 1;\n                $ret['msg'] = $mail->ErrorInfo;\n                return $ret;\n            }\n        }\n        // return $mail->Send() ? true : $mail->ErrorInfo;\n    }\n```\n\n## SMTP配置函数\n\n```php\n// 配置邮件发送服务器\n'THINK_EMAIL'=>array(\n    'SMTP_HOST'   =>  'localhost',  //邮件发送SMTP服务器\n    'SMTP_PORT'   => '25',//SMTP服务器端口  \n    'SMTP_USER'   =>  'admin', //SMTP服务器登陆用户名\n    'SMTP_PASS'   =>  'admin', //SMTP服务器登陆密码 \n    'FROM_EMAIL'  =>'发件箱@XX.com',\n    'FROM_NAME'  =>'发件人姓名',\n    'REPLY_EMAIL' =>'',\n    'REPLY_NAME'  =>'',\n    'EMAIL_CHARSET' =>'utf-8',\n    'EMAIL_ISHTML' => 'TRUE',\n    'EMAIL_SMTPAUTH' => '0',\n    ),\n```\n\n## 根据库中存取的base64获取图片信息，实际调用为一个url\n\n```php\npublic function getImage() {\n    $reportId = I('request.id');\n    $imgInfos = I('request.img');\n    header('Content-Type: image/png');\n    $repotModel = M('XXX');\n    $report = $repotModel->where(['id'=>$reportId])->find();\n    $base = explode(',', $report[$imgInfos])[1];\n    $base = base64_decode($base);\n    echo $base;\n    die();\n}\n```\n\n","tags":["PHP"],"categories":["2.Programming","PHP"]},{"title":"PHP之Pchart生产图片","url":"/2.Programming/2.PHP/PHP之Pchart生产图片/","content":"\n[pChart online documentation](http://wiki.pchart.net/doc.introduction.html)\n\n[实例](http://pchart.sourceforge.net/index.php)\n\n ","tags":["PHP"],"categories":["2.Programming","PHP"]},{"title":"PHP导出Excel","url":"/2.Programming/2.PHP/PHP导出Excel/","content":"\n## 引入相关公共库PHPExcel\n\n## 编写公共函数\n\n```php\npublic function exportExcel($excelTitle,$data,$filename='',$column_width=''){\n        ini_set('max_execution_time', '0');\n        header(\"Content-Type:application/force-download\");\n        header(\"Content-Type:application/vnd.ms-execl\");\n        header(\"Content-Type:application/download\");\n        $filename=str_replace('.xls', '', $filename).'.xls';\n        header('Content-Disposition: attachment;filename='.$filename);\n        Vendor('PHPExcel.PHPExcel');\n        $phpexcel = new PHPExcel();\n        $phpexcel->getActiveSheet()->setTitle('Sheet1');\n\n        $key = 0;  //设置表头\n        foreach($excelTitle as $v){\n            $colum = \\PHPExcel_Cell::stringFromColumnIndex($key);\n            $phpexcel->setActiveSheetIndex(0) ->setCellValue($colum.'1', $v);\n            $key += 1;\n        }\n        $column = 2;\n        $objActSheet = $phpexcel->getActiveSheet();\n\n        foreach($data as $key => $rows){ //行写入\n            $span = 0;\n            foreach($rows as $keyName=>$value){// 列写入\n                $j = \\PHPExcel_Cell::stringFromColumnIndex($span);\n                $objActSheet->setCellValue($j.$column, $value);\n                $span++;\n            }\n            $column++;\n        }\n\n        //设置字体格式及大小\n        $phpexcel->getDefaultStyle()->getFont()->setName( '微软雅黑');\n        $phpexcel->getDefaultStyle()->getFont()->setSize(10);\n\n        //第一行设置填充的样式和背景色\n        $currentColumn = 'A';\n        for ($i = 1; $i <= count($excelTitle); $i++) {\n            $a[] = $currentColumn++;\n        }\n        $last = $a[(count($a) -1)].\"1\";\n        $phpexcel->getActiveSheet()->getStyle( \"A1:$last\")->getFill()->setFillType(\\PHPExcel_Style_Fill::FILL_SOLID);\n        $phpexcel->getActiveSheet()->getStyle( \"A1:$last\")->getFill()->getStartColor()->setARGB('#458B00');\n\n        //设置单元格内容居左显示\n        //$phpexcel->getActiveSheet()->getStyle('A')->getAlignment()->setHorizontal(\\PHPExcel_Style_Alignment::HORIZONTAL_JUSTIFY);\n        $phpexcel->getDefaultStyle()->getAlignment()->setHorizontal(\\PHPExcel_Style_Alignment::HORIZONTAL_JUSTIFY);\n        $phpexcel->getDefaultStyle()->getAlignment()->setVertical(\\PHPExcel_Style_Alignment::HORIZONTAL_JUSTIFY);\n\n        //设置列宽度\n        if(!empty($column_width)){\n            foreach($column_width as $key => $value){\n                $phpexcel->getActiveSheet()->getColumnDimension($key)->setWidth($value);\n            }\n        }\n\n        $objwriter = PHPExcel_IOFactory::createWriter($phpexcel, 'Excel5');\n        $objwriter->save('php://output');\n        exit;\n    }\n```\n\n## 调用公共函数\n\n```php\n$excelTitle = array(\"提测单名称\",\"BUG统计周期\",\"BUG_TOTAL\",\"ASSIGNED\",\"REOPENED\",\"RESOLVED\",\"VERIFIED\",\"CLOSED\");\nforeach ($retSearchStatusList as $excelExport){\n    $excelExports['A'] = $excelExport['A'];\n    $excelExports['B'] = $dateFrom.\"至\".$dateTo;\n    $excelExports['C'] = $excelExport['C'];\n    $excelExports['D'] = $excelExport['D'];\n    $excelExports['E'] = $excelExport['E'];\n    $excelExports['F'] = $excelExport['F'];\n    $excelExports['G'] = $excelExport['G'];\n    $excelExports['H'] = $excelExport['H'];\n    $list[] = $excelExports;\n}\n$filename = \"文件名称-\".date('Y-m-d H-i-s');\n$column_width = array(\"A\"=>50,\"B\"=>38);\n$exportExcel = $excelUtil->exportExcel($excelTitle,$list,$filename,$column_width);\n```\n\n","tags":["PHP"],"categories":["2.Programming","PHP"]}]